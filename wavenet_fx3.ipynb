{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 4th root for embedding: https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combined forex and economic news data\n",
    "df = pd.read_csv('fx_with_news.csv', header=[0,1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">c_eur</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">after_counter_ohe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>bar_len</th>\n",
       "      <th>bar_spearman</th>\n",
       "      <th>bar_log_r</th>\n",
       "      <th>first_r</th>\n",
       "      <th>max_r</th>\n",
       "      <th>min_r</th>\n",
       "      <th>last_r</th>\n",
       "      <th>bar_quantile_25_r</th>\n",
       "      <th>...</th>\n",
       "      <th>_united states nondefense capital goods orders ex aircraft</th>\n",
       "      <th>_united states nonfarm payrolls</th>\n",
       "      <th>_united states retail sales control group</th>\n",
       "      <th>_united states retail sales ex autos mom</th>\n",
       "      <th>_united states retail sales mom</th>\n",
       "      <th>_united states reutersmichigan consumer sentiment index</th>\n",
       "      <th>_united states trade balance</th>\n",
       "      <th>_united states unemployment rate</th>\n",
       "      <th>_usd event</th>\n",
       "      <th>_usd speech</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:00:00</th>\n",
       "      <td>1.087467</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.737459</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:05:00</th>\n",
       "      <td>1.087362</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-0.181051</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:10:00</th>\n",
       "      <td>1.086980</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-0.460522</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:15:00</th>\n",
       "      <td>1.086938</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.282268</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:20:00</th>\n",
       "      <td>1.087057</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-0.043127</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:35:00</th>\n",
       "      <td>1.121460</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.800736</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972569</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:40:00</th>\n",
       "      <td>1.121460</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.141550</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:45:00</th>\n",
       "      <td>1.121388</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.612689</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:50:00</th>\n",
       "      <td>1.121327</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-0.912678</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:55:00</th>\n",
       "      <td>1.121247</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298829 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        c_eur                                           \\\n",
       "                         mean       std bar_len bar_spearman bar_log_r   \n",
       "ctime                                                                    \n",
       "2016-01-03 22:00:00  1.087467  0.000015    28.0    -0.737459 -0.000037   \n",
       "2016-01-03 22:05:00  1.087362  0.000049   155.0    -0.181051 -0.000230   \n",
       "2016-01-03 22:10:00  1.086980  0.000105   138.0    -0.460522 -0.000248   \n",
       "2016-01-03 22:15:00  1.086938  0.000043   125.0     0.282268 -0.000028   \n",
       "2016-01-03 22:20:00  1.087057  0.000148   115.0    -0.043127 -0.000120   \n",
       "...                       ...       ...     ...          ...       ...   \n",
       "2019-12-31 21:35:00  1.121460  0.000037    62.0    -0.800736 -0.000080   \n",
       "2019-12-31 21:40:00  1.121460  0.000028    41.0    -0.141550 -0.000009   \n",
       "2019-12-31 21:45:00  1.121388  0.000046   108.0     0.612689 -0.000018   \n",
       "2019-12-31 21:50:00  1.121327  0.000046    97.0    -0.912678 -0.000143   \n",
       "2019-12-31 21:55:00  1.121247  0.000131    91.0     0.075062  0.000294   \n",
       "\n",
       "                                                                               \\\n",
       "                      first_r     max_r     min_r    last_r bar_quantile_25_r   \n",
       "ctime                                                                           \n",
       "2016-01-03 22:00:00  0.000030  0.000030 -0.000016 -0.000007         -0.000009   \n",
       "2016-01-03 22:05:00  0.000081  0.000081 -0.000149 -0.000149         -0.000029   \n",
       "2016-01-03 22:10:00  0.000203  0.000203 -0.000147 -0.000046         -0.000064   \n",
       "2016-01-03 22:15:00 -0.000007  0.000057 -0.000108 -0.000035         -0.000007   \n",
       "2016-01-03 22:20:00 -0.000144  0.000224 -0.000264 -0.000264         -0.000126   \n",
       "...                       ...       ...       ...       ...               ...   \n",
       "2019-12-31 21:35:00  0.000062  0.000062 -0.000036 -0.000018         -0.000027   \n",
       "2019-12-31 21:40:00 -0.000027  0.000035 -0.000054 -0.000036         -0.000018   \n",
       "2019-12-31 21:45:00  0.000029  0.000047 -0.000096  0.000011         -0.000025   \n",
       "2019-12-31 21:50:00  0.000056  0.000092 -0.000122 -0.000086         -0.000015   \n",
       "2019-12-31 21:55:00 -0.000033  0.000261 -0.000123  0.000261         -0.000078   \n",
       "\n",
       "                     ...  \\\n",
       "                     ...   \n",
       "ctime                ...   \n",
       "2016-01-03 22:00:00  ...   \n",
       "2016-01-03 22:05:00  ...   \n",
       "2016-01-03 22:10:00  ...   \n",
       "2016-01-03 22:15:00  ...   \n",
       "2016-01-03 22:20:00  ...   \n",
       "...                  ...   \n",
       "2019-12-31 21:35:00  ...   \n",
       "2019-12-31 21:40:00  ...   \n",
       "2019-12-31 21:45:00  ...   \n",
       "2019-12-31 21:50:00  ...   \n",
       "2019-12-31 21:55:00  ...   \n",
       "\n",
       "                                                             after_counter_ohe  \\\n",
       "                    _united states nondefense capital goods orders ex aircraft   \n",
       "ctime                                                                            \n",
       "2016-01-03 22:00:00                                           0.000000           \n",
       "2016-01-03 22:05:00                                           0.000000           \n",
       "2016-01-03 22:10:00                                           0.000000           \n",
       "2016-01-03 22:15:00                                           0.000000           \n",
       "2016-01-03 22:20:00                                           0.000000           \n",
       "...                                                                ...           \n",
       "2019-12-31 21:35:00                                           0.429514           \n",
       "2019-12-31 21:40:00                                           0.429167           \n",
       "2019-12-31 21:45:00                                           0.428819           \n",
       "2019-12-31 21:50:00                                           0.428472           \n",
       "2019-12-31 21:55:00                                           0.428125           \n",
       "\n",
       "                                                     \\\n",
       "                    _united states nonfarm payrolls   \n",
       "ctime                                                 \n",
       "2016-01-03 22:00:00                             0.0   \n",
       "2016-01-03 22:05:00                             0.0   \n",
       "2016-01-03 22:10:00                             0.0   \n",
       "2016-01-03 22:15:00                             0.0   \n",
       "2016-01-03 22:20:00                             0.0   \n",
       "...                                             ...   \n",
       "2019-12-31 21:35:00                             0.0   \n",
       "2019-12-31 21:40:00                             0.0   \n",
       "2019-12-31 21:45:00                             0.0   \n",
       "2019-12-31 21:50:00                             0.0   \n",
       "2019-12-31 21:55:00                             0.0   \n",
       "\n",
       "                                                               \\\n",
       "                    _united states retail sales control group   \n",
       "ctime                                                           \n",
       "2016-01-03 22:00:00                                       0.0   \n",
       "2016-01-03 22:05:00                                       0.0   \n",
       "2016-01-03 22:10:00                                       0.0   \n",
       "2016-01-03 22:15:00                                       0.0   \n",
       "2016-01-03 22:20:00                                       0.0   \n",
       "...                                                       ...   \n",
       "2019-12-31 21:35:00                                       0.0   \n",
       "2019-12-31 21:40:00                                       0.0   \n",
       "2019-12-31 21:45:00                                       0.0   \n",
       "2019-12-31 21:50:00                                       0.0   \n",
       "2019-12-31 21:55:00                                       0.0   \n",
       "\n",
       "                                                              \\\n",
       "                    _united states retail sales ex autos mom   \n",
       "ctime                                                          \n",
       "2016-01-03 22:00:00                                      0.0   \n",
       "2016-01-03 22:05:00                                      0.0   \n",
       "2016-01-03 22:10:00                                      0.0   \n",
       "2016-01-03 22:15:00                                      0.0   \n",
       "2016-01-03 22:20:00                                      0.0   \n",
       "...                                                      ...   \n",
       "2019-12-31 21:35:00                                      0.0   \n",
       "2019-12-31 21:40:00                                      0.0   \n",
       "2019-12-31 21:45:00                                      0.0   \n",
       "2019-12-31 21:50:00                                      0.0   \n",
       "2019-12-31 21:55:00                                      0.0   \n",
       "\n",
       "                                                     \\\n",
       "                    _united states retail sales mom   \n",
       "ctime                                                 \n",
       "2016-01-03 22:00:00                             0.0   \n",
       "2016-01-03 22:05:00                             0.0   \n",
       "2016-01-03 22:10:00                             0.0   \n",
       "2016-01-03 22:15:00                             0.0   \n",
       "2016-01-03 22:20:00                             0.0   \n",
       "...                                             ...   \n",
       "2019-12-31 21:35:00                             0.0   \n",
       "2019-12-31 21:40:00                             0.0   \n",
       "2019-12-31 21:45:00                             0.0   \n",
       "2019-12-31 21:50:00                             0.0   \n",
       "2019-12-31 21:55:00                             0.0   \n",
       "\n",
       "                                                                             \\\n",
       "                    _united states reutersmichigan consumer sentiment index   \n",
       "ctime                                                                         \n",
       "2016-01-03 22:00:00                                                0.0        \n",
       "2016-01-03 22:05:00                                                0.0        \n",
       "2016-01-03 22:10:00                                                0.0        \n",
       "2016-01-03 22:15:00                                                0.0        \n",
       "2016-01-03 22:20:00                                                0.0        \n",
       "...                                                                ...        \n",
       "2019-12-31 21:35:00                                                0.0        \n",
       "2019-12-31 21:40:00                                                0.0        \n",
       "2019-12-31 21:45:00                                                0.0        \n",
       "2019-12-31 21:50:00                                                0.0        \n",
       "2019-12-31 21:55:00                                                0.0        \n",
       "\n",
       "                                                  \\\n",
       "                    _united states trade balance   \n",
       "ctime                                              \n",
       "2016-01-03 22:00:00                          0.0   \n",
       "2016-01-03 22:05:00                          0.0   \n",
       "2016-01-03 22:10:00                          0.0   \n",
       "2016-01-03 22:15:00                          0.0   \n",
       "2016-01-03 22:20:00                          0.0   \n",
       "...                                          ...   \n",
       "2019-12-31 21:35:00                          0.0   \n",
       "2019-12-31 21:40:00                          0.0   \n",
       "2019-12-31 21:45:00                          0.0   \n",
       "2019-12-31 21:50:00                          0.0   \n",
       "2019-12-31 21:55:00                          0.0   \n",
       "\n",
       "                                                                             \n",
       "                    _united states unemployment rate _usd event _usd speech  \n",
       "ctime                                                                        \n",
       "2016-01-03 22:00:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:05:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:10:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:15:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:20:00                              0.0   0.000000         0.0  \n",
       "...                                              ...        ...         ...  \n",
       "2019-12-31 21:35:00                              0.0   0.972569         0.0  \n",
       "2019-12-31 21:40:00                              0.0   0.972222         0.0  \n",
       "2019-12-31 21:45:00                              0.0   0.971875         0.0  \n",
       "2019-12-31 21:50:00                              0.0   0.971528         0.0  \n",
       "2019-12-31 21:55:00                              0.0   0.971181         0.0  \n",
       "\n",
       "[298829 rows x 459 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of currencies\n",
    "c_list = ['c_eur', 'c_gbp', 'c_jpy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new feature for more stable forecast\n",
    "for cur in c_list:    \n",
    "    # logreturn of the means\n",
    "    df[(cur,'mean_log_r')] = np.log(1.0 + df[(cur,'mean')].pct_change())\n",
    "    df[(cur,'mean_log_r')] = df[(cur,'mean_log_r')].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "TOP COLUMN:  c_eur\n",
      "SUBCOLUMNS:  12\n",
      "['mean', 'std', 'bar_len', 'bar_spearman', 'bar_log_r', 'first_r', 'max_r', 'min_r', 'last_r', 'bar_quantile_25_r', 'bar_quantile_75_r', 'mean_log_r']\n",
      "----------------------------------\n",
      "TOP COLUMN:  c_gbp\n",
      "SUBCOLUMNS:  12\n",
      "['mean', 'std', 'bar_len', 'bar_spearman', 'bar_log_r', 'first_r', 'max_r', 'min_r', 'last_r', 'bar_quantile_25_r', 'bar_quantile_75_r', 'mean_log_r']\n",
      "----------------------------------\n",
      "TOP COLUMN:  c_jpy\n",
      "SUBCOLUMNS:  12\n",
      "['mean', 'std', 'bar_len', 'bar_spearman', 'bar_log_r', 'first_r', 'max_r', 'min_r', 'last_r', 'bar_quantile_25_r', 'bar_quantile_75_r', 'mean_log_r']\n",
      "----------------------------------\n",
      "TOP COLUMN:  month\n",
      "SUBCOLUMNS:  12\n",
      "['_1', '_2', '_3', '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11', '_12']\n",
      "----------------------------------\n",
      "TOP COLUMN:  dow\n",
      "SUBCOLUMNS:  6\n",
      "['_0', '_1', '_2', '_3', '_4', '_6']\n",
      "----------------------------------\n",
      "TOP COLUMN:  hour\n",
      "SUBCOLUMNS:  24\n",
      "['_0', '_1', '_2', '_3', '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11', '_12', '_13', '_14', '_15', '_16', '_17', '_18', '_19', '_20', '_21', '_22', '_23']\n",
      "----------------------------------\n",
      "TOP COLUMN:  event_cur\n",
      "SUBCOLUMNS:  4\n",
      "['_EUR', '_GBP', '_JPY', '_USD']\n",
      "----------------------------------\n",
      "TOP COLUMN:  event_exist\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  actual_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  surprise_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  change_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  after_counter_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n"
     ]
    }
   ],
   "source": [
    "# column hierarchy\n",
    "for top in list(df.columns.get_level_values(0).unique()):\n",
    "    print('----------------------------------')\n",
    "    print('TOP COLUMN: ', top)\n",
    "    print('SUBCOLUMNS: ', len(df[top].columns))\n",
    "    print(list(df[top].columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c_eur',\n",
       " 'c_gbp',\n",
       " 'c_jpy',\n",
       " 'month',\n",
       " 'dow',\n",
       " 'hour',\n",
       " 'event_cur',\n",
       " 'event_exist',\n",
       " 'actual_ohe',\n",
       " 'surprise_ohe',\n",
       " 'change_ohe',\n",
       " 'after_counter_ohe']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_level = list(df.columns.get_level_values(0).unique())\n",
    "top_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use 2016-2018 as training data, and 2019 as validation and test data\n",
    "# problem: we have events that occure only in 2019\n",
    "# we can't normalize/standardize/scale them based on 2016-2018 data\n",
    "# we could move them to the '_(currency) event' columns, \n",
    "# but there is only a few, so here I will delete them\n",
    "\n",
    "# have we all event type in 2016-2018 yers?\n",
    "df['event_exist'].loc['2016':'2019'].any().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_european monetary union markit pmi composite',\n",
       " '_germany zew survey  economic sentiment',\n",
       " '_japan gross domestic product qoq',\n",
       " '_united states consumer price index ex food  energy mom',\n",
       " '_united states initial jobless claims 4week average',\n",
       " '_united states nondefense capital goods orders ex aircraft']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find events occuring only in 2019\n",
    "event_before_19 = df['event_exist'].loc['2016':'2019'].any()\n",
    "event_only_19 = list(event_before_19[event_before_19==False].index)\n",
    "event_only_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop events only occuring in 2019\n",
    "df.drop(event_only_19, axis=1, level=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have we all event type in 2016-2018 yers?\n",
    "df['event_exist'].loc['2016':'2019'].any().all()\n",
    "#ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:00:00</th>\n",
       "      <td>1.087467</td>\n",
       "      <td>1.473700</td>\n",
       "      <td>0.831731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:05:00</th>\n",
       "      <td>1.087362</td>\n",
       "      <td>1.474204</td>\n",
       "      <td>0.831720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:10:00</th>\n",
       "      <td>1.086980</td>\n",
       "      <td>1.474567</td>\n",
       "      <td>0.831713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:15:00</th>\n",
       "      <td>1.086938</td>\n",
       "      <td>1.474208</td>\n",
       "      <td>0.831647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:20:00</th>\n",
       "      <td>1.087057</td>\n",
       "      <td>1.474157</td>\n",
       "      <td>0.831599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:35:00</th>\n",
       "      <td>1.121460</td>\n",
       "      <td>1.324929</td>\n",
       "      <td>0.920382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:40:00</th>\n",
       "      <td>1.121460</td>\n",
       "      <td>1.325454</td>\n",
       "      <td>0.920438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:45:00</th>\n",
       "      <td>1.121388</td>\n",
       "      <td>1.326264</td>\n",
       "      <td>0.920370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:50:00</th>\n",
       "      <td>1.121327</td>\n",
       "      <td>1.326356</td>\n",
       "      <td>0.920378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:55:00</th>\n",
       "      <td>1.121247</td>\n",
       "      <td>1.326194</td>\n",
       "      <td>0.920179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        c_eur     c_gbp     c_jpy\n",
       "                         mean      mean      mean\n",
       "ctime                                            \n",
       "2016-01-03 22:00:00  1.087467  1.473700  0.831731\n",
       "2016-01-03 22:05:00  1.087362  1.474204  0.831720\n",
       "2016-01-03 22:10:00  1.086980  1.474567  0.831713\n",
       "2016-01-03 22:15:00  1.086938  1.474208  0.831647\n",
       "2016-01-03 22:20:00  1.087057  1.474157  0.831599\n",
       "...                       ...       ...       ...\n",
       "2019-12-31 21:35:00  1.121460  1.324929  0.920382\n",
       "2019-12-31 21:40:00  1.121460  1.325454  0.920438\n",
       "2019-12-31 21:45:00  1.121388  1.326264  0.920370\n",
       "2019-12-31 21:50:00  1.121327  1.326356  0.920378\n",
       "2019-12-31 21:55:00  1.121247  1.326194  0.920179\n",
       "\n",
       "[298829 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rescaling output isn't always important, \n",
    "# but if the model has different output features it helps to weight their effect on the loss function\n",
    "# or we can use multiple loss functions and manually set the weight\n",
    "df_label = df.xs('mean', axis=1, level=1, drop_level=False)\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use only train and validation\n",
    "# Standardizing and normalizing shifts the dataset, where +- sign can be important. Later the model will adjust this by the biases,\n",
    "# but the information is lost. It could improve the performance if we make a new feature for + and - numbers, but here I don't want to make more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spearman doesn't need standardization\n",
    "c_single_features = ['mean', 'std', 'bar_len']\n",
    "feature_scalers = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features based on data up to 2019-01-01 00:00\n",
    "for cur in c_list:\n",
    "    for feature in c_single_features:\n",
    "        column_mean = df[cur, feature].loc['2016':'2019'].mean()\n",
    "        column_std = df[cur, feature].loc['2016':'2019'].std()\n",
    "        feature_scalers.update({(cur, feature) : [column_mean, column_std]})\n",
    "        df.loc[:,(cur, feature)] = (df[cur, feature] - column_mean)/column_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('c_eur', 'mean'): [1.1392483015708013, 0.04998154896157088],\n",
       " ('c_eur', 'std'): [0.00010543836669119064, 9.077071115943414e-05],\n",
       " ('c_eur', 'bar_len'): [412.9294628759021, 381.7685744752956],\n",
       " ('c_gbp', 'mean'): [1.3263368732176204, 0.06648514955410852],\n",
       " ('c_gbp', 'std'): [0.0001466428489918478, 0.0001589000772232711],\n",
       " ('c_gbp', 'bar_len'): [387.5186401063365, 303.3104183503984],\n",
       " ('c_jpy', 'mean'): [0.906695470940815, 0.033451362417663416],\n",
       " ('c_jpy', 'std'): [9.80057991353974e-05, 9.589094629696239e-05],\n",
       " ('c_jpy', 'bar_len'): [354.61210380295637, 299.81779856624456]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!! later we can use them to rescale if needed\n",
    "feature_scalers # column_mean, column_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_log_r           1435.641469\n",
      "bar_log_r            1756.307094\n",
      "first_r              1079.158746\n",
      "max_r                1680.077984\n",
      "min_r                1686.788765\n",
      "last_r                960.660734\n",
      "bar_quantile_25_r     647.482120\n",
      "bar_quantile_75_r     647.172621\n",
      "dtype: float64\n",
      "mean_log_r              1.023680\n",
      "bar_log_r               8.380970\n",
      "first_r                -0.840415\n",
      "max_r                1680.077984\n",
      "min_r               -1686.788765\n",
      "last_r                  7.540555\n",
      "bar_quantile_25_r    -647.041955\n",
      "bar_quantile_75_r     646.659518\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "c_related_features = ['mean_log_r','bar_log_r','first_r','max_r','min_r','last_r','bar_quantile_25_r','bar_quantile_75_r']\n",
    "# these are related feature, we can think of them as one feature with subfeatures\n",
    "# they are on similar scale \n",
    "# and the pairs on the other side of the mean (like max_r and min_r) are almost symmetric\n",
    "# to preserve the signs we don't subtract the mean, only divide by the std\n",
    "# this way we preserve their relative size\n",
    "# *10000000 is only for easier comparison\n",
    "print(df['c_eur'][c_related_features].abs().mean()*10000000)\n",
    "print(df['c_eur'][c_related_features].mean()*10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_std = df[cur, 'bar_log_r'].loc['2016':'2019'].std()\n",
    "\n",
    "for cur in c_list:\n",
    "    for feature in c_related_features:\n",
    "        df.loc[:,(cur, feature)] = (df[cur, feature])/related_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00035617512187632297"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!! needed later to rescale outputs of log_r features\n",
    "related_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_log_r           0.403072\n",
      "bar_log_r            0.493102\n",
      "first_r              0.302985\n",
      "max_r                0.471700\n",
      "min_r                0.473584\n",
      "last_r               0.269716\n",
      "bar_quantile_25_r    0.181788\n",
      "bar_quantile_75_r    0.181701\n",
      "dtype: float64\n",
      "mean_log_r           0.000287\n",
      "bar_log_r            0.002353\n",
      "first_r             -0.000236\n",
      "max_r                0.471700\n",
      "min_r               -0.473584\n",
      "last_r               0.002117\n",
      "bar_quantile_25_r   -0.181664\n",
      "bar_quantile_75_r    0.181557\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ok, these features remained on similar scale, but the other features as well\n",
    "print(df['c_eur'][c_related_features].abs().mean())\n",
    "print(df['c_eur'][c_related_features].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean_log_r</th>\n",
       "      <th>mean_log_r</th>\n",
       "      <th>mean_log_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:05:00</th>\n",
       "      <td>-0.271969</td>\n",
       "      <td>0.959393</td>\n",
       "      <td>-0.038811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:10:00</th>\n",
       "      <td>-0.986573</td>\n",
       "      <td>0.692598</td>\n",
       "      <td>-0.022978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:15:00</th>\n",
       "      <td>-0.108544</td>\n",
       "      <td>-0.684034</td>\n",
       "      <td>-0.222788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:20:00</th>\n",
       "      <td>0.306975</td>\n",
       "      <td>-0.096665</td>\n",
       "      <td>-0.160975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:35:00</th>\n",
       "      <td>-0.048386</td>\n",
       "      <td>0.197334</td>\n",
       "      <td>-0.022041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:40:00</th>\n",
       "      <td>-0.000601</td>\n",
       "      <td>1.112390</td>\n",
       "      <td>0.169539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:45:00</th>\n",
       "      <td>-0.182122</td>\n",
       "      <td>1.715093</td>\n",
       "      <td>-0.207541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:50:00</th>\n",
       "      <td>-0.151968</td>\n",
       "      <td>0.194708</td>\n",
       "      <td>0.026822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:55:00</th>\n",
       "      <td>-0.198915</td>\n",
       "      <td>-0.343131</td>\n",
       "      <td>-0.608848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         c_eur      c_gbp      c_jpy\n",
       "                    mean_log_r mean_log_r mean_log_r\n",
       "ctime                                               \n",
       "2016-01-03 22:00:00   0.000000   0.000000   0.000000\n",
       "2016-01-03 22:05:00  -0.271969   0.959393  -0.038811\n",
       "2016-01-03 22:10:00  -0.986573   0.692598  -0.022978\n",
       "2016-01-03 22:15:00  -0.108544  -0.684034  -0.222788\n",
       "2016-01-03 22:20:00   0.306975  -0.096665  -0.160975\n",
       "...                        ...        ...        ...\n",
       "2019-12-31 21:35:00  -0.048386   0.197334  -0.022041\n",
       "2019-12-31 21:40:00  -0.000601   1.112390   0.169539\n",
       "2019-12-31 21:45:00  -0.182122   1.715093  -0.207541\n",
       "2019-12-31 21:50:00  -0.151968   0.194708   0.026822\n",
       "2019-12-31 21:55:00  -0.198915  -0.343131  -0.608848\n",
       "\n",
       "[298829 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_return = df.xs('mean_log_r', axis=1, level=1, drop_level=False)\n",
    "df_label_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_EUR    2.000000\n",
       "_GBP    2.828427\n",
       "_JPY    1.732051\n",
       "_USD    3.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'event_cur' is on similar scale, we don't touch (normalization would be better than standardization)\n",
    "df['event_cur'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should consider every event type alone, but there are 76 event types, so just normalize\n",
    "df['actual_ohe'] = (df['actual_ohe'] - df['actual_ohe'].loc['2016':'2019'].min())/(df['actual_ohe'].loc['2016':'2019'].max() - df['actual_ohe'].loc['2016':'2019'].min())\n",
    "# where max-min == 0 we get NaN, fill with 0\n",
    "df['actual_ohe'] = df['actual_ohe'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing with the max of absolute values keeps the signs\n",
    "df['surprise_ohe'] = df['surprise_ohe']/df['surprise_ohe'].loc['2016':'2019'].abs().max()\n",
    "df['surprise_ohe'] = df['surprise_ohe'].fillna(0.0)\n",
    "\n",
    "df['change_ohe'] = df['change_ohe']/df['change_ohe'].loc['2016':'2019'].abs().max()\n",
    "df['change_ohe'] = df['change_ohe'].fillna(0.0)\n",
    "\n",
    "df['after_counter_ohe'] = df['after_counter_ohe']/df['after_counter_ohe'].loc['2016':'2019'].abs().max()\n",
    "df['after_counter_ohe'] = df['after_counter_ohe'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_label = df_label.astype('float16')\n",
    "# df = df.astype('float16')\n",
    "df_valid = df.loc['2019':]\n",
    "df = df.loc[:'2019']\n",
    "df_label_valid = df_label.loc['2019':]\n",
    "df_label = df_label.loc[:'2019']\n",
    "df_label_return_valid = df_label_return.loc['2019':]\n",
    "df_label_return = df_label_return.loc[:'2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1175694609369098\n",
      "0.23388258061315467\n"
     ]
    }
   ],
   "source": [
    "print(df.std().max())\n",
    "print(df.std().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_eur event                                                 187122\n",
       "_eur speech                                                126077\n",
       "_european monetary union consumer price index  core yoy    148270\n",
       "_european monetary union consumer price index yoy          148270\n",
       "_european monetary union ecb deposit rate decision          63360\n",
       "                                                            ...  \n",
       "_united states reutersmichigan consumer sentiment index     60480\n",
       "_united states trade balance                               103680\n",
       "_united states unemployment rate                            74880\n",
       "_usd event                                                 172408\n",
       "_usd speech                                                208368\n",
       "Length: 70, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['after_counter_ohe'][df['after_counter_ohe']>0.0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001977906033436539"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean average error of no_price change\n",
    "(df_label - df_label.shift()).abs().mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631797140944485"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean average error of no_return_change\n",
    "# this data is scaled !!!, should multiply with related_std for real magnitude\n",
    "(df_label_return - df_label_return.shift()).abs().mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49374693981256845"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the erro of the no_price_change forecast with returns:\n",
    "# this data is scaled !!!, should multiply with related_std for real magnitude\n",
    "df_label_return.abs().mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=144\n",
    "shift=1\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label data begins from the end of the first train data\n",
    "\n",
    "def ds_input(df, concat_tops, feature_to_last):\n",
    "    nx = df.to_numpy()\n",
    "    if (isinstance(df.columns, pd.MultiIndex) and concat_tops==False):\n",
    "        top_level_nb = len(df.columns.get_level_values(0).unique())\n",
    "        sub_level_nb = len(df.columns.get_level_values(1).unique())\n",
    "        nx = nx.reshape(-1,top_level_nb,sub_level_nb)\n",
    "        if feature_to_last == True:\n",
    "            nx = np.moveaxis(nx, [0,1,2], [0,2,1])\n",
    "        nx = np.squeeze(nx)\n",
    "    return nx\n",
    "\n",
    "def make_ds(batch_size, time_steps, shift, skip_steps, df, concat_tops=False, feature_to_last=True):\n",
    "    nx = ds_input(df, concat_tops, feature_to_last)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(nx[skip_steps:])\n",
    "    ds = ds.window(time_steps, shift=shift, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(time_steps))\n",
    "    return ds.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset_args = {'batch_size':batch_size,\n",
    "                      'time_steps':train_size,\n",
    "                      'shift':shift, \n",
    "                      'skip_steps':1}\n",
    "\n",
    "ds_label = make_ds(**label_dataset_args, df=df_label)\n",
    "ds_label_valid = make_ds(**label_dataset_args, df=df_label_valid)\n",
    "\n",
    "ds_label_return = make_ds(**label_dataset_args, df=df_label_return)\n",
    "ds_label_return_valid = make_ds(**label_dataset_args, df=df_label_return_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_args = {'batch_size':batch_size,\n",
    "                      'time_steps':train_size,\n",
    "                      'shift':shift, \n",
    "                      'skip_steps':0}\n",
    "\n",
    "ds_full = make_ds(**input_dataset_args, df=df, concat_tops=True)\n",
    "ds_full_valid = make_ds(**input_dataset_args, df=df_valid, concat_tops=True)\n",
    "\n",
    "ds_curbars = make_ds(**input_dataset_args, df=df[['c_eur', 'c_gbp', 'c_jpy']], concat_tops=True)\n",
    "ds_curbars_valid = make_ds(**input_dataset_args, df=df_valid[['c_eur', 'c_gbp', 'c_jpy']], concat_tops=True)\n",
    "\n",
    "ds_event_exist = make_ds(**input_dataset_args, df=df['event_exist'])\n",
    "ds_event_exist_valid = make_ds(**input_dataset_args, df=df_valid['event_exist'])\n",
    "\n",
    "ds_nosparse = make_ds(**input_dataset_args, df=df[['surprise_ohe', 'after_counter_ohe']], concat_tops=False, feature_to_last=True)\n",
    "ds_nosparse_valid = make_ds(**input_dataset_args, df=df_valid[['surprise_ohe', 'after_counter_ohe']], concat_tops=False, feature_to_last=True)\n",
    "\n",
    "ds_eventcur = make_ds(**input_dataset_args, df=df['event_cur'], concat_tops=True)\n",
    "ds_eventcur_valid = make_ds(**input_dataset_args, df=df_valid['event_cur'], concat_tops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dataset_args = {'batch_size':batch_size,\n",
    "                      'time_steps':train_size,\n",
    "                      'shift':shift, \n",
    "                      'skip_steps':1}\n",
    "\n",
    "ds_future = make_ds(**future_dataset_args, df=df[['event_exist', 'month', 'dow', 'hour', 'event_cur']], concat_tops=True)\n",
    "ds_future_valid = make_ds(**future_dataset_args, df=df_valid[['event_exist', 'month', 'dow', 'hour', 'event_cur']], concat_tops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_label  <BatchDataset shapes: (64, None, 3), types: tf.float64>\n",
      "ds_label  <BatchDataset shapes: (64, None, 3), types: tf.float64>\n",
      "ds_full  <BatchDataset shapes: (64, None, 432), types: tf.float64>\n",
      "ds_curbars  <BatchDataset shapes: (64, None, 36), types: tf.float64>\n",
      "ds_event_exist  <BatchDataset shapes: (64, None, 70), types: tf.float64>\n",
      "ds_nosparse  <BatchDataset shapes: (64, None, 70, 2), types: tf.float64>\n",
      "ds_eventcur  <BatchDataset shapes: (64, None, 4), types: tf.float64>\n",
      "ds_future  <BatchDataset shapes: (64, None, 116), types: tf.float64>\n"
     ]
    }
   ],
   "source": [
    "print('ds_label ',ds_label)\n",
    "print('ds_label ',ds_label_return)\n",
    "\n",
    "print('ds_full ', ds_full)\n",
    "print('ds_curbars ', ds_curbars)\n",
    "print('ds_event_exist ', ds_event_exist)\n",
    "print('ds_nosparse ', ds_nosparse)\n",
    "print('ds_eventcur ', ds_eventcur)\n",
    "\n",
    "print('ds_future ', ds_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedActivationUnit(keras.layers.Layer):\n",
    "    def __init__(self, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'activation': self.activation,\n",
    "        })\n",
    "        return config \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        n_filters = inputs.shape[-1] // 2\n",
    "        linear_output = self.activation(inputs[..., :n_filters])\n",
    "        gate = keras.activations.sigmoid(inputs[..., n_filters:])\n",
    "        return self.activation(linear_output) * gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavenet_residual_block(inputs, n_filters, dilation_rate):\n",
    "    z = keras.layers.Conv1D(2 * n_filters, kernel_size=2, padding=\"causal\",\n",
    "                            dilation_rate=dilation_rate)(inputs)\n",
    "    z = GatedActivationUnit()(z)\n",
    "    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)\n",
    "    return keras.layers.Add()([z, inputs]), z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavenet_model_setup(n_layers_per_block, n_blocks, n_filters, n_outputs, feature_dim, name, last_activation='relu'):\n",
    "    # n_layers_per_block = 10 in the paper\n",
    "    # n_blocks = 3 in the paper\n",
    "    # n_filters = 128 in the paper\n",
    "    # n_outputs = 256 in the paper\n",
    "    \n",
    "    inputs = keras.layers.Input(shape=[train_size, feature_dim]) # 164 with cross model\n",
    "    z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)\n",
    "    skip_to_last = []\n",
    "    for dilation_rate in [2**i for i in range(n_layers_per_block)] * n_blocks:\n",
    "        z, skip = wavenet_residual_block(z, n_filters, dilation_rate)\n",
    "        skip_to_last.append(skip)\n",
    "    z = keras.activations.relu(keras.layers.Add()(skip_to_last))\n",
    "    z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)\n",
    "    out = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=last_activation)(z)\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[out], name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_embed_setup(inputs, embed_dim, name=None):\n",
    "    out = keras.layers.Conv1D(embed_dim, kernel_size=1, strides=1, padding='valid')(inputs)\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7454314533808187e-05\n",
      "0.011860263878605136\n"
     ]
    }
   ],
   "source": [
    "# event_exist is extremly sparse\n",
    "print(df['event_exist'].sum(axis=1).sum()/(df.shape[0]*df.shape[1]))\n",
    "print(df['event_exist'].sum(axis=1).sum()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "input_event_exist = keras.layers.Input(shape=[train_size, 70], name = 'input_event_exist') \n",
    "input_nosparse = keras.layers.Input(shape=[train_size, 70, 2], name = 'input_nosparse')\n",
    "input_eventcur = keras.layers.Input(shape=[train_size, 4], name = 'input_eventcur')\n",
    "input_curbars = keras.layers.Input(shape=[train_size, 36], name = 'input_curbars')\n",
    "input_full = keras.layers.Input(shape=[train_size, 432], name = 'input_full')\n",
    "\n",
    "input_future = keras.layers.Input(shape=[train_size, 116], name = 'input_future')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Simplest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mod_wavenet_fl64_fd36\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 144, 36)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 144, 64)      4672        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 144, 128)     16512       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit (GatedAct (None, 144, 64)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 144, 64)      4160        gated_activation_unit[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 144, 64)      0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 144, 128)     16512       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_1 (GatedA (None, 144, 64)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 144, 64)      4160        gated_activation_unit_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 144, 64)      0           conv1d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 144, 128)     16512       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_2 (GatedA (None, 144, 64)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 144, 64)      4160        gated_activation_unit_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 144, 64)      0           conv1d_6[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 144, 128)     16512       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_3 (GatedA (None, 144, 64)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 144, 64)      4160        gated_activation_unit_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 144, 64)      0           conv1d_8[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 144, 128)     16512       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_4 (GatedA (None, 144, 64)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 144, 64)      4160        gated_activation_unit_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 144, 64)      0           conv1d_10[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 144, 128)     16512       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_5 (GatedA (None, 144, 64)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 144, 64)      4160        gated_activation_unit_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 144, 64)      0           conv1d_12[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 144, 128)     16512       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_6 (GatedA (None, 144, 64)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 144, 64)      4160        gated_activation_unit_6[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 144, 64)      0           conv1d_14[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 144, 128)     16512       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_7 (GatedA (None, 144, 64)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 144, 64)      4160        gated_activation_unit_7[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 144, 64)      0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu (TensorFlowOpL [(None, 144, 64)]    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 144, 64)      4160        tf_op_layer_Relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 144, 3)       195         conv1d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 174,403\n",
      "Trainable params: 174,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_wn = wavenet_model_setup(n_layers_per_block=4, n_blocks=2, n_filters=64, n_outputs=3, feature_dim=36, name='mod_wavenet_fl64_fd36')\n",
    "model_wn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_curbars (InputLayer)   [(None, 144, 36)]         0         \n",
      "_________________________________________________________________\n",
      "mod_wavenet_fl64_fd36 (Model (None, 144, 3)            174403    \n",
      "=================================================================\n",
      "Total params: 174,403\n",
      "Trainable params: 174,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wave_out = model_wn(input_curbars)\n",
    "\n",
    "model_no_f = keras.models.Model(inputs=[input_curbars], outputs=[wave_out])\n",
    "\n",
    "model_no_f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.zip((ds_curbars, ds_label)).shuffle(128, reshuffle_each_iteration=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_valid = tf.data.Dataset.zip((ds_curbars_valid, ds_label_valid)).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3500/3500 [==============================] - 206s 59ms/step - loss: 9.9472e-04 - mae: 0.0139 - val_loss: 1.8738e-05 - val_mae: 0.0042\n",
      "Epoch 2/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 7.1254e-05 - mae: 0.0056 - val_loss: 6.6615e-06 - val_mae: 0.0026\n",
      "Epoch 3/25\n",
      "3500/3500 [==============================] - 194s 56ms/step - loss: 4.8545e-05 - mae: 0.0054 - val_loss: 6.8264e-06 - val_mae: 0.0023\n",
      "Epoch 4/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 2.5057e-05 - mae: 0.0044 - val_loss: 9.9226e-06 - val_mae: 0.0034\n",
      "Epoch 5/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 4.0205e-05 - mae: 0.0044 - val_loss: 2.5743e-06 - val_mae: 0.0013\n",
      "Epoch 6/25\n",
      "3500/3500 [==============================] - 194s 55ms/step - loss: 1.9656e-05 - mae: 0.0038 - val_loss: 6.9021e-06 - val_mae: 0.0028\n",
      "Epoch 7/25\n",
      "3500/3500 [==============================] - 198s 57ms/step - loss: 1.9963e-05 - mae: 0.0037 - val_loss: 2.1450e-06 - val_mae: 0.0015\n",
      "Epoch 8/25\n",
      "3500/3500 [==============================] - 197s 56ms/step - loss: 1.8014e-05 - mae: 0.0036 - val_loss: 3.2692e-06 - val_mae: 0.0019\n",
      "Epoch 9/25\n",
      "3500/3500 [==============================] - 193s 55ms/step - loss: 1.9169e-05 - mae: 0.0035 - val_loss: 4.0691e-06 - val_mae: 0.0022\n",
      "Epoch 10/25\n",
      "3500/3500 [==============================] - 195s 56ms/step - loss: 1.4368e-05 - mae: 0.0032 - val_loss: 2.5435e-06 - val_mae: 0.0016\n",
      "Epoch 11/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 1.1961e-05 - mae: 0.0027 - val_loss: 1.8734e-06 - val_mae: 0.0014\n",
      "Epoch 12/25\n",
      "3500/3500 [==============================] - 195s 56ms/step - loss: 1.4821e-05 - mae: 0.0029 - val_loss: 1.6997e-06 - val_mae: 0.0014\n",
      "Epoch 13/25\n",
      "3500/3500 [==============================] - 198s 56ms/step - loss: 1.1909e-05 - mae: 0.0028 - val_loss: 1.8974e-06 - val_mae: 0.0015\n",
      "Epoch 14/25\n",
      "3500/3500 [==============================] - 193s 55ms/step - loss: 1.4910e-05 - mae: 0.0027 - val_loss: 2.0633e-06 - val_mae: 0.0014\n",
      "Epoch 15/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 1.0733e-05 - mae: 0.0024 - val_loss: 7.6293e-07 - val_mae: 8.9781e-04\n",
      "Epoch 16/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 1.3927e-05 - mae: 0.0024 - val_loss: 8.3950e-07 - val_mae: 9.9756e-04\n",
      "Epoch 17/25\n",
      "3500/3500 [==============================] - 194s 55ms/step - loss: 1.1133e-05 - mae: 0.0023 - val_loss: 1.0967e-06 - val_mae: 0.0011\n",
      "Epoch 18/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 1.1397e-05 - mae: 0.0024 - val_loss: 9.6005e-07 - val_mae: 0.0010\n",
      "Epoch 19/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 1.4053e-05 - mae: 0.0025 - val_loss: 1.1942e-06 - val_mae: 0.0012\n",
      "Epoch 20/25\n",
      "3500/3500 [==============================] - 195s 56ms/step - loss: 7.4426e-06 - mae: 0.0022 - val_loss: 5.1171e-07 - val_mae: 7.7754e-04\n",
      "Epoch 21/25\n",
      "3500/3500 [==============================] - 197s 56ms/step - loss: 6.2656e-06 - mae: 0.0021 - val_loss: 3.0838e-07 - val_mae: 5.9392e-04\n",
      "Epoch 22/25\n",
      "3500/3500 [==============================] - 194s 56ms/step - loss: 8.4531e-06 - mae: 0.0019 - val_loss: 6.6561e-07 - val_mae: 8.4481e-04\n",
      "Epoch 23/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 7.5724e-06 - mae: 0.0020 - val_loss: 4.1321e-07 - val_mae: 6.6522e-04\n",
      "Epoch 24/25\n",
      "3500/3500 [==============================] - 196s 56ms/step - loss: 4.8973e-06 - mae: 0.0019 - val_loss: 1.1460e-06 - val_mae: 0.0014\n",
      "Epoch 25/25\n",
      "3500/3500 [==============================] - 191s 55ms/step - loss: 5.1974e-06 - mae: 0.0017 - val_loss: 1.5454e-06 - val_mae: 0.0017\n"
     ]
    }
   ],
   "source": [
    "#optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "#model_no_f.compile(loss=keras.losses.Huber(), optimizer=optimizer, metrics=[\"mae\"])\n",
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_wn_no_f_b.h5\", save_best_only=True)\n",
    "\n",
    "#history = model_no_f.fit(ds_train, epochs=25,\n",
    "#                       validation_data=ds_valid,\n",
    "#                       callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Simple Model with economic news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_news\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_nosparse (InputLayer)     [(None, 144, 70, 2)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 144, 70, 6)   18          input_nosparse[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 144, 70, 6)   24          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 144, 70, 1)   7           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 144, 70)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_eventcur (InputLayer)     [(None, 144, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 144, 74)      0           reshape[0][0]                    \n",
      "                                                                 input_eventcur[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 144, 10)      750         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 799\n",
      "Trainable params: 787\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dicrease dimension of economic data\n",
    "i_nosprs = keras.layers.Conv2D(6, kernel_size=1, padding=\"valid\", activation='relu')(input_nosparse)\n",
    "i_nosprs = keras.layers.BatchNormalization()(i_nosprs)\n",
    "i_nosprs = keras.layers.Conv2D(1, kernel_size=1, padding=\"valid\", activation='relu')(i_nosprs)\n",
    "i_nosprs = keras.layers.Reshape([train_size,70])(i_nosprs)\n",
    "\n",
    "i_news = keras.layers.Concatenate()([i_nosprs, input_eventcur])\n",
    "i_news = keras.layers.Conv1D(10, kernel_size=1, strides=1, padding='valid')(i_news)\n",
    "\n",
    "model_news = keras.models.Model(inputs=[input_nosparse, input_eventcur], outputs=[i_news], name='model_news')\n",
    "\n",
    "model_news.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wn = wavenet_model_setup(n_layers_per_block=4, n_blocks=2, n_filters=96, n_outputs=3, feature_dim=46, name='mod_wavenet_fl96_fd46')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer input_eventcur.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: input_eventcur:0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_nosparse (InputLayer)     [(None, 144, 70, 2)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_eventcur (InputLayer)     [(None, 144, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_curbars (InputLayer)      [(None, 144, 36)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_news (Model)              (None, 144, 10)      799         input_nosparse[0][0]             \n",
      "                                                                 input_eventcur[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 144, 46)      0           input_curbars[0][0]              \n",
      "                                                                 model_news[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mod_wavenet_fl96_fd46 (Model)   (None, 144, 3)       389475      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 390,274\n",
      "Trainable params: 390,262\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_news = model_news([input_nosparse, input_eventcur])\n",
    "\n",
    "input_wn = keras.layers.Concatenate(axis=-1)([input_curbars, input_news])\n",
    "\n",
    "wave_out = model_wn(input_wn)\n",
    "\n",
    "model_no_f_nosparse = keras.models.Model(inputs=[input_curbars, input_nosparse, input_eventcur], outputs=[wave_out])\n",
    "\n",
    "model_no_f_nosparse.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.zip(((ds_curbars, ds_nosparse, ds_eventcur), ds_label)).shuffle(128, reshuffle_each_iteration=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_valid = tf.data.Dataset.zip(((ds_curbars_valid, ds_nosparse_valid, ds_eventcur_valid), ds_label_valid)).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 414s 118ms/step - loss: 0.0016 - mae: 0.0207 - val_loss: 2.0989e-04 - val_mae: 0.0169\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 1.0873e-04 - mae: 0.0090 - val_loss: 3.0817e-05 - val_mae: 0.0067\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 5.3788e-05 - mae: 0.0060 - val_loss: 6.8537e-06 - val_mae: 0.0027\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 3.4718e-05 - mae: 0.0050 - val_loss: 8.7216e-06 - val_mae: 0.0028\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 3.4288e-05 - mae: 0.0050 - val_loss: 7.1162e-06 - val_mae: 0.0027\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 2.9983e-05 - mae: 0.0042 - val_loss: 2.9439e-06 - val_mae: 0.0018\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 392s 112ms/step - loss: 1.9494e-05 - mae: 0.0036 - val_loss: 2.4329e-06 - val_mae: 0.0016\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 412s 118ms/step - loss: 2.2592e-05 - mae: 0.0039 - val_loss: 6.1452e-06 - val_mae: 0.0023\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 1.3415e-05 - mae: 0.0031 - val_loss: 2.8999e-06 - val_mae: 0.0017\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 1.3591e-05 - mae: 0.0033 - val_loss: 3.8285e-06 - val_mae: 0.0022\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 1.3912e-05 - mae: 0.0028 - val_loss: 4.6362e-06 - val_mae: 0.0022\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 408s 116ms/step - loss: 1.3117e-05 - mae: 0.0029 - val_loss: 5.6683e-06 - val_mae: 0.0024\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 1.0964e-05 - mae: 0.0028 - val_loss: 1.0236e-05 - val_mae: 0.0029\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 408s 116ms/step - loss: 1.1405e-05 - mae: 0.0028 - val_loss: 6.0899e-06 - val_mae: 0.0026\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 1.4790e-05 - mae: 0.0028 - val_loss: 5.7354e-06 - val_mae: 0.0025\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 1.2959e-05 - mae: 0.0026 - val_loss: 3.4465e-06 - val_mae: 0.0021\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 8.3723e-06 - mae: 0.0023 - val_loss: 4.7828e-06 - val_mae: 0.0023\n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 7.1347e-06 - mae: 0.0022 - val_loss: 1.6532e-06 - val_mae: 0.0013\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 7.6145e-06 - mae: 0.0024 - val_loss: 2.5787e-06 - val_mae: 0.0016\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 7.5083e-06 - mae: 0.0021 - val_loss: 1.2452e-06 - val_mae: 9.5435e-04\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 411s 117ms/step - loss: 6.2708e-06 - mae: 0.0021 - val_loss: 1.0331e-06 - val_mae: 0.0010\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 5.9098e-06 - mae: 0.0020 - val_loss: 1.1424e-06 - val_mae: 0.0011\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 7.6752e-06 - mae: 0.0021 - val_loss: 1.6360e-06 - val_mae: 0.0015\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 8.7195e-06 - mae: 0.0022 - val_loss: 8.8748e-07 - val_mae: 9.0447e-04\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 6.4604e-06 - mae: 0.0021 - val_loss: 1.0830e-06 - val_mae: 0.0011\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 395s 113ms/step - loss: 6.2839e-06 - mae: 0.0018 - val_loss: 1.7334e-06 - val_mae: 0.0014\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 416s 119ms/step - loss: 7.3242e-06 - mae: 0.0019 - val_loss: 3.9583e-07 - val_mae: 6.3814e-04\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 5.9773e-06 - mae: 0.0019 - val_loss: 4.7999e-06 - val_mae: 0.0026\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 6.2468e-06 - mae: 0.0017 - val_loss: 7.6601e-07 - val_mae: 9.8372e-04\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 4.9363e-06 - mae: 0.0018 - val_loss: 7.7391e-07 - val_mae: 9.4854e-04\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 9.4076e-06 - mae: 0.0020 - val_loss: 9.8696e-07 - val_mae: 0.0011\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 6.6095e-06 - mae: 0.0017 - val_loss: 1.4223e-06 - val_mae: 0.0013\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 6.8151e-06 - mae: 0.0018 - val_loss: 6.5576e-07 - val_mae: 8.3824e-04\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 5.9463e-06 - mae: 0.0018 - val_loss: 1.0813e-06 - val_mae: 9.7524e-04\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 5.0089e-06 - mae: 0.0018 - val_loss: 8.7135e-07 - val_mae: 0.0011\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 3.3401e-06 - mae: 0.0014 - val_loss: 4.3534e-07 - val_mae: 6.9674e-04\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 3.6108e-06 - mae: 0.0015 - val_loss: 3.5065e-07 - val_mae: 6.8539e-04\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 3.8351e-06 - mae: 0.0015 - val_loss: 2.0287e-07 - val_mae: 4.5886e-04\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 4.3632e-06 - mae: 0.0016 - val_loss: 2.0406e-07 - val_mae: 4.9704e-04\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 3.7390e-06 - mae: 0.0015 - val_loss: 9.7425e-07 - val_mae: 0.0012\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_no_f_nosparse.compile(loss=keras.losses.Huber(), optimizer=optimizer, metrics=[\"mae\"])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_nofut_nosparse.h5\", save_best_only=True)\n",
    "\n",
    "#history = model_no_f_nosparse.fit(ds_train, epochs=40,\n",
    "#                       validation_data=ds_valid,\n",
    "#                       callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_back = keras.models.load_model(\"model_nofut_nosparse.h5\", custom_objects={'GatedActivationUnit' : GatedActivationUnit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 5.2693e-06 - mae: 0.0016 - val_loss: 4.8368e-07 - val_mae: 7.6866e-04\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 3.1530e-06 - mae: 0.0014 - val_loss: 2.5354e-07 - val_mae: 5.1345e-04\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 408s 116ms/step - loss: 3.3944e-06 - mae: 0.0013 - val_loss: 3.0894e-07 - val_mae: 6.1697e-04\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 4.0766e-06 - mae: 0.0015 - val_loss: 3.7216e-07 - val_mae: 7.2735e-04\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 391s 112ms/step - loss: 2.8135e-06 - mae: 0.0013 - val_loss: 3.5234e-07 - val_mae: 6.5486e-04\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 413s 118ms/step - loss: 7.9496e-06 - mae: 0.0018 - val_loss: 7.7137e-07 - val_mae: 9.3843e-04\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 3.7275e-06 - mae: 0.0015 - val_loss: 3.3031e-07 - val_mae: 5.9646e-04\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 7.0889e-06 - mae: 0.0016 - val_loss: 3.0416e-07 - val_mae: 5.6121e-04\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 2.6352e-06 - mae: 0.0013 - val_loss: 3.5359e-07 - val_mae: 6.5010e-04\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 3.6191e-06 - mae: 0.0015 - val_loss: 1.7292e-07 - val_mae: 4.4553e-04e-0 - ETA: 0s - loss: 3.6283e-06 - ma\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 4.1364e-06 - mae: 0.0014 - val_loss: 8.9407e-07 - val_mae: 8.0759e-04\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 4.9558e-06 - mae: 0.0014 - val_loss: 1.8769e-06 - val_mae: 0.0013\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 2.7149e-06 - mae: 0.0013 - val_loss: 1.5702e-07 - val_mae: 3.9612e-04\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 4.5189e-06 - mae: 0.0013 - val_loss: 1.2146e-07 - val_mae: 3.5252e-04\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 2.8571e-06 - mae: 0.0013 - val_loss: 1.3605e-07 - val_mae: 3.6293e-04\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 408s 116ms/step - loss: 4.3993e-06 - mae: 0.0014 - val_loss: 1.6680e-07 - val_mae: 4.1565e-04\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 2.7498e-06 - mae: 0.0012 - val_loss: 1.5105e-07 - val_mae: 4.1600e-04\n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 3.4729e-06 - mae: 0.0012 - val_loss: 2.3403e-07 - val_mae: 5.4853e-04\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 2.5525e-06 - mae: 0.0012 - val_loss: 1.2391e-06 - val_mae: 0.0015\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 2.4680e-06 - mae: 0.0012 - val_loss: 3.7322e-07 - val_mae: 6.7489e-04\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 2.2974e-06 - mae: 0.0012 - val_loss: 8.4465e-08 - val_mae: 2.3895e-04\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 3.0506e-06 - mae: 0.0012 - val_loss: 4.2635e-07 - val_mae: 7.3634e-04\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 2.5427e-06 - mae: 0.0013 - val_loss: 9.4872e-07 - val_mae: 0.0013\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 390s 111ms/step - loss: 2.6720e-06 - mae: 0.0012 - val_loss: 1.1927e-07 - val_mae: 3.3582e-04\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - 413s 118ms/step - loss: 4.0208e-06 - mae: 0.0013 - val_loss: 1.4832e-07 - val_mae: 3.9043e-04\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 3.0632e-06 - mae: 0.0011 - val_loss: 2.3136e-07 - val_mae: 4.8428e-04\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 2.6396e-06 - mae: 0.0011 - val_loss: 1.7080e-07 - val_mae: 4.5318e-04\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 408s 116ms/step - loss: 2.3423e-06 - mae: 0.0012 - val_loss: 1.7605e-07 - val_mae: 4.3290e-04\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 2.6600e-06 - mae: 0.0012 - val_loss: 7.6897e-07 - val_mae: 0.0011\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 2.5721e-06 - mae: 0.0011 - val_loss: 6.8495e-07 - val_mae: 0.0010\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 413s 118ms/step - loss: 3.7067e-06 - mae: 0.0013 - val_loss: 3.7436e-07 - val_mae: 6.7769e-04\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 411s 117ms/step - loss: 3.1095e-06 - mae: 0.0012 - val_loss: 2.7778e-07 - val_mae: 5.8508e-04\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 408s 117ms/step - loss: 1.7911e-06 - mae: 0.0011 - val_loss: 2.3447e-07 - val_mae: 5.5397e-04\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 411s 117ms/step - loss: 1.7947e-06 - mae: 0.0010 - val_loss: 1.2783e-07 - val_mae: 3.8953e-04\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 410s 117ms/step - loss: 2.0390e-06 - mae: 0.0011 - val_loss: 2.3872e-07 - val_mae: 5.6104e-04\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 409s 117ms/step - loss: 1.4990e-06 - mae: 9.9401e-04 - val_loss: 1.8053e-07 - val_mae: 4.8426e-04\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 411s 117ms/step - loss: 2.4215e-06 - mae: 0.0011 - val_loss: 1.8432e-07 - val_mae: 4.6885e-04\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 412s 118ms/step - loss: 2.5133e-06 - mae: 0.0010 - val_loss: 1.1019e-07 - val_mae: 3.5069e-04\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 2.4213e-06 - mae: 0.0011 - val_loss: 1.8489e-07 - val_mae: 5.1214e-04\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 408s 116ms/step - loss: 2.6083e-06 - mae: 0.0011 - val_loss: 1.1569e-07 - val_mae: 3.5540e-04\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_nofut_nosparse.h5\", save_best_only=True)\n",
    "\n",
    "#history = model_no_f_nosparse.fit(ds_train, epochs=40,\n",
    "#                       validation_data=ds_valid,\n",
    "#                       callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_direct = keras.models.load_model(\"model_nofut_nosparse.h5\", custom_objects={'GatedActivationUnit' : GatedActivationUnit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1163/Unknown - 92s 79ms/step - loss: 8.4465e-08 - mae: 2.3895e-04"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.446481664240753e-08, 0.00023895457]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_direct.evaluate(ds_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with Returns and Relu output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_acc(y_true, y_pred):\n",
    "    return tf.where(tf.math.greater((y_true[:,-1,:] * y_pred[:,-1,:]), 0.0), 1.0, 0.0)\n",
    "def direction_inacc(y_true, y_pred):\n",
    "    return tf.where(tf.math.less((y_true[:,-1,:] * y_pred[:,-1,:]), 0.0), 1.0, 0.0)\n",
    "\n",
    "def true_zero(y_true, y_pred):\n",
    "    return tf.where(tf.math.equal(y_true[:,-1,:], 0.0), 1.0, 0.0)\n",
    "def pred_zero(y_true, y_pred):\n",
    "    return tf.where(tf.math.equal(y_pred[:,-1,:], 0.0), 1.0, 0.0)\n",
    "\n",
    "def direction_acc_pos(y_true, y_pred):\n",
    "    return tf.where(\n",
    "                    tf.math.logical_and(tf.math.greater((y_true[:,-1,:] * y_pred[:,-1,:]), 0.0), \n",
    "                                        tf.math.greater(y_true[:,-1,:], 0.0)),\n",
    "                    1.0, 0.0)\n",
    "\n",
    "def direction_acc_neg(y_true, y_pred):\n",
    "    return tf.where(\n",
    "                    tf.math.logical_and(tf.math.greater((y_true[:,-1,:] * y_pred[:,-1,:]), 0.0), \n",
    "                                        tf.math.less(y_true[:,-1,:], 0.0)),\n",
    "                    1.0, 0.0)\n",
    "\n",
    "def direction_inacc_pos(y_true, y_pred):\n",
    "    return tf.where(\n",
    "                    tf.math.logical_and(tf.math.less((y_true[:,-1,:] * y_pred[:,-1,:]), 0.0), \n",
    "                                        tf.math.greater(y_true[:,-1,:], 0.0)),\n",
    "                    1.0, 0.0)\n",
    "\n",
    "def direction_inacc_neg(y_true, y_pred):\n",
    "    return tf.where(\n",
    "                    tf.math.logical_and(tf.math.less((y_true[:,-1,:] * y_pred[:,-1,:]), 0.0), \n",
    "                                        tf.math.less(y_true[:,-1,:], 0.0)),\n",
    "                    1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.zip(((ds_curbars, ds_nosparse, ds_eventcur), ds_label_return)).shuffle(128, reshuffle_each_iteration=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_valid = tf.data.Dataset.zip(((ds_curbars_valid, ds_nosparse_valid, ds_eventcur_valid), ds_label_return_valid)).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_news\" was not an Input tensor, it was generated by layer input_eventcur.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: input_eventcur:0\n"
     ]
    }
   ],
   "source": [
    "# dicrease dimension of economic data\n",
    "i_nosprs = keras.layers.Conv2D(6, kernel_size=1, padding=\"valid\", activation='relu')(input_nosparse)\n",
    "i_nosprs = keras.layers.BatchNormalization()(i_nosprs)\n",
    "i_nosprs = keras.layers.Conv2D(1, kernel_size=1, padding=\"valid\", activation='relu')(i_nosprs)\n",
    "i_nosprs = keras.layers.Reshape([train_size,70])(i_nosprs)\n",
    "\n",
    "i_news = keras.layers.Concatenate()([i_nosprs, input_eventcur])\n",
    "i_news = keras.layers.Conv1D(10, kernel_size=1, strides=1, padding='valid')(i_news)\n",
    "\n",
    "model_news = keras.models.Model(inputs=[input_nosparse, input_eventcur], outputs=[i_news], name='model_news')\n",
    "\n",
    "model_wn = wavenet_model_setup(n_layers_per_block=4, n_blocks=2, n_filters=96, n_outputs=3, feature_dim=46, name='mod_wavenet_fl96_fd46')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer input_eventcur.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: input_eventcur:0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_nosparse (InputLayer)     [(None, 144, 70, 2)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_eventcur (InputLayer)     [(None, 144, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_curbars (InputLayer)      [(None, 144, 36)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_news (Model)              (None, 144, 10)      799         input_nosparse[0][0]             \n",
      "                                                                 input_eventcur[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 144, 46)      0           input_curbars[0][0]              \n",
      "                                                                 model_news[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mod_wavenet_fl96_fd46 (Model)   (None, 144, 3)       389475      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 390,274\n",
      "Trainable params: 390,262\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_news = model_news([input_nosparse, input_eventcur])\n",
    "\n",
    "input_wn = keras.layers.Concatenate(axis=-1)([input_curbars, input_news])\n",
    "\n",
    "wave_out = model_wn(input_wn)\n",
    "\n",
    "model_ret_pos = keras.models.Model(inputs=[input_curbars, input_nosparse, input_eventcur], outputs=[wave_out])\n",
    "\n",
    "model_ret_pos.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3500/3500 [==============================] - 398s 114ms/step - loss: 0.1823 - mae: 0.4400 - direction_acc: 0.3195 - direction_inacc: 0.1162 - pred_zero: 0.5643 - val_loss: 0.1097 - val_mae: 0.3199 - val_direction_acc: 0.3519 - val_direction_inacc: 0.1422 - val_pred_zero: 0.5058\n",
      "Epoch 2/5\n",
      "3500/3500 [==============================] - 393s 112ms/step - loss: 0.1790 - mae: 0.4347 - direction_acc: 0.3390 - direction_inacc: 0.1219 - pred_zero: 0.5391 - val_loss: 0.1096 - val_mae: 0.3191 - val_direction_acc: 0.3337 - val_direction_inacc: 0.1240 - val_pred_zero: 0.5423\n",
      "Epoch 3/5\n",
      "3500/3500 [==============================] - 392s 112ms/step - loss: 0.1772 - mae: 0.4322 - direction_acc: 0.3353 - direction_inacc: 0.1165 - pred_zero: 0.5481 - val_loss: 0.1097 - val_mae: 0.3189 - val_direction_acc: 0.3225 - val_direction_inacc: 0.1167 - val_pred_zero: 0.5608\n",
      "Epoch 4/5\n",
      "3500/3500 [==============================] - 395s 113ms/step - loss: 0.1760 - mae: 0.4306 - direction_acc: 0.3282 - direction_inacc: 0.1100 - pred_zero: 0.5618 - val_loss: 0.1105 - val_mae: 0.3204 - val_direction_acc: 0.3132 - val_direction_inacc: 0.1089 - val_pred_zero: 0.5779\n",
      "Epoch 5/5\n",
      "3500/3500 [==============================] - 398s 114ms/step - loss: 0.1753 - mae: 0.4297 - direction_acc: 0.3287 - direction_inacc: 0.1096 - pred_zero: 0.5618 - val_loss: 0.1108 - val_mae: 0.3211 - val_direction_acc: 0.3272 - val_direction_inacc: 0.1198 - val_pred_zero: 0.5530\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_ret_pos.compile(loss=keras.losses.Huber(), optimizer=optimizer, metrics=[\"mae\", direction_acc, direction_inacc, pred_zero])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_return_pos.h5\", save_best_only=True)\n",
    "\n",
    "history = model_ret_pos.fit(ds_train, epochs=5,\n",
    "                       validation_data=ds_valid,\n",
    "                       callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with Returns and negative Relu output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_news\" was not an Input tensor, it was generated by layer input_eventcur.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: input_eventcur:0\n"
     ]
    }
   ],
   "source": [
    "# dicrease dimension of economic data\n",
    "i_nosprs = keras.layers.Conv2D(6, kernel_size=1, padding=\"valid\", activation='relu')(input_nosparse)\n",
    "i_nosprs = keras.layers.BatchNormalization()(i_nosprs)\n",
    "i_nosprs = keras.layers.Conv2D(1, kernel_size=1, padding=\"valid\", activation='relu')(i_nosprs)\n",
    "i_nosprs = keras.layers.Reshape([train_size,70])(i_nosprs)\n",
    "\n",
    "i_news = keras.layers.Concatenate()([i_nosprs, input_eventcur])\n",
    "i_news = keras.layers.Conv1D(10, kernel_size=1, strides=1, padding='valid')(i_news)\n",
    "\n",
    "model_news = keras.models.Model(inputs=[input_nosparse, input_eventcur], outputs=[i_news], name='model_news')\n",
    "\n",
    "model_wn = wavenet_model_setup(n_layers_per_block=4, n_blocks=2, n_filters=96, n_outputs=3, feature_dim=46, name='mod_wavenet_fl96_fd46', last_activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer input_eventcur.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: input_eventcur:0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_nosparse (InputLayer)     [(None, 144, 70, 2)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_eventcur (InputLayer)     [(None, 144, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_curbars (InputLayer)      [(None, 144, 36)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_news (Model)              (None, 144, 10)      799         input_nosparse[0][0]             \n",
      "                                                                 input_eventcur[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 144, 46)      0           input_curbars[0][0]              \n",
      "                                                                 model_news[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mod_wavenet_fl96_fd46 (Model)   (None, 144, 3)       389475      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 144, 3)       0           mod_wavenet_fl96_fd46[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 144, 3)       0           activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 390,274\n",
      "Trainable params: 390,262\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_news = model_news([input_nosparse, input_eventcur])\n",
    "\n",
    "input_wn = keras.layers.Concatenate(axis=-1)([input_curbars, input_news])\n",
    "\n",
    "wave_out = model_wn(input_wn)\n",
    "\n",
    "out = keras.layers.Activation('relu')(wave_out)\n",
    "\n",
    "out = keras.layers.Lambda(lambda x: x * -1.0)(out)\n",
    "\n",
    "model_ret_neg = keras.models.Model(inputs=[input_curbars, input_nosparse, input_eventcur], outputs=[out])\n",
    "\n",
    "model_ret_neg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3500/3500 [==============================] - 398s 114ms/step - loss: 0.1842 - mae: 0.4422 - direction_acc: 0.3133 - direction_inacc: 0.1154 - pred_zero: 0.5713 - val_loss: 0.1096 - val_mae: 0.3194 - val_direction_acc: 0.3149 - val_direction_inacc: 0.1129 - val_pred_zero: 0.5722\n",
      "Epoch 2/5\n",
      "3500/3500 [==============================] - 394s 112ms/step - loss: 0.1787 - mae: 0.4340 - direction_acc: 0.3407 - direction_inacc: 0.1215 - pred_zero: 0.5378 - val_loss: 0.1094 - val_mae: 0.3187 - val_direction_acc: 0.3025 - val_direction_inacc: 0.0997 - val_pred_zero: 0.5978\n",
      "Epoch 3/5\n",
      "3500/3500 [==============================] - 395s 113ms/step - loss: 0.1772 - mae: 0.4321 - direction_acc: 0.3377 - direction_inacc: 0.1171 - pred_zero: 0.5452 - val_loss: 0.1101 - val_mae: 0.3196 - val_direction_acc: 0.3422 - val_direction_inacc: 0.1343 - val_pred_zero: 0.5235\n",
      "Epoch 4/5\n",
      "3500/3500 [==============================] - 400s 114ms/step - loss: 0.1760 - mae: 0.4305 - direction_acc: 0.3328 - direction_inacc: 0.1123 - pred_zero: 0.5549 - val_loss: 0.1109 - val_mae: 0.3211 - val_direction_acc: 0.2962 - val_direction_inacc: 0.0968 - val_pred_zero: 0.6070\n",
      "Epoch 5/5\n",
      "3500/3500 [==============================] - 393s 112ms/step - loss: 0.1754 - mae: 0.4297 - direction_acc: 0.3279 - direction_inacc: 0.1076 - pred_zero: 0.5644 - val_loss: 0.1111 - val_mae: 0.3214 - val_direction_acc: 0.3167 - val_direction_inacc: 0.1130 - val_pred_zero: 0.5703\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_ret_neg.compile(loss=keras.losses.Huber(), optimizer=optimizer, metrics=[\"mae\", direction_acc, direction_inacc, pred_zero])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_return_neg.h5\", save_best_only=True)\n",
    "\n",
    "history = model_ret_neg.fit(ds_train, epochs=5,\n",
    "                       validation_data=ds_valid,\n",
    "                       callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with Returns and No-Activation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_news\" was not an Input tensor, it was generated by layer input_eventcur.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: input_eventcur:0\n"
     ]
    }
   ],
   "source": [
    "# dicrease dimension of economic data\n",
    "i_nosprs = keras.layers.Conv2D(6, kernel_size=1, padding=\"valid\", activation='relu')(input_nosparse)\n",
    "i_nosprs = keras.layers.BatchNormalization()(i_nosprs)\n",
    "i_nosprs = keras.layers.Conv2D(1, kernel_size=1, padding=\"valid\", activation='relu')(i_nosprs)\n",
    "i_nosprs = keras.layers.Reshape([train_size,70])(i_nosprs)\n",
    "\n",
    "i_news = keras.layers.Concatenate()([i_nosprs, input_eventcur])\n",
    "i_news = keras.layers.Conv1D(10, kernel_size=1, strides=1, padding='valid')(i_news)\n",
    "\n",
    "model_news = keras.models.Model(inputs=[input_nosparse, input_eventcur], outputs=[i_news], name='model_news')\n",
    "\n",
    "model_wn = wavenet_model_setup(n_layers_per_block=4, n_blocks=2, n_filters=96, n_outputs=3, feature_dim=46, name='mod_wavenet_fl96_fd46', last_activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer input_eventcur.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: input_eventcur:0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_nosparse (InputLayer)     [(None, 144, 70, 2)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_eventcur (InputLayer)     [(None, 144, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_curbars (InputLayer)      [(None, 144, 36)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_news (Model)              (None, 144, 10)      799         input_nosparse[0][0]             \n",
      "                                                                 input_eventcur[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 144, 46)      0           input_curbars[0][0]              \n",
      "                                                                 model_news[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mod_wavenet_fl96_fd46 (Model)   (None, 144, 3)       389475      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 390,274\n",
      "Trainable params: 390,262\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_news = model_news([input_nosparse, input_eventcur])\n",
    "\n",
    "input_wn = keras.layers.Concatenate(axis=-1)([input_curbars, input_news])\n",
    "\n",
    "wave_out = model_wn(input_wn)\n",
    "\n",
    "model_ret_noact = keras.models.Model(inputs=[input_curbars, input_nosparse, input_eventcur], outputs=[wave_out])\n",
    "\n",
    "model_ret_noact.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3500/3500 [==============================] - 403s 115ms/step - loss: 0.1431 - mae: 0.3818 - direction_acc: 0.7165 - direction_inacc: 0.2834 - pred_zero: 0.0000e+00 - direction_acc_pos: 0.3580 - direction_inacc_pos: 0.1410 - direction_acc_neg: 0.3585 - direction_inacc_neg: 0.1425 - val_loss: 0.0892 - val_mae: 0.2845 - val_direction_acc: 0.7075 - val_direction_inacc: 0.2925 - val_pred_zero: 0.0000e+00 - val_direction_acc_pos: 0.3152 - val_direction_inacc_pos: 0.1849 - val_direction_acc_neg: 0.3923 - val_direction_inacc_neg: 0.1075\n",
      "Epoch 2/5\n",
      "3500/3500 [==============================] - 394s 113ms/step - loss: 0.1385 - mae: 0.3747 - direction_acc: 0.7237 - direction_inacc: 0.2763 - pred_zero: 0.0000e+00 - direction_acc_pos: 0.3615 - direction_inacc_pos: 0.1375 - direction_acc_neg: 0.3622 - direction_inacc_neg: 0.1388 - val_loss: 0.0888 - val_mae: 0.2835 - val_direction_acc: 0.7075 - val_direction_inacc: 0.2925 - val_pred_zero: 0.0000e+00 - val_direction_acc_pos: 0.3865 - val_direction_inacc_pos: 0.1137 - val_direction_acc_neg: 0.3210 - val_direction_inacc_neg: 0.1788\n",
      "Epoch 3/5\n",
      "3500/3500 [==============================] - 397s 114ms/step - loss: 0.1359 - mae: 0.3711 - direction_acc: 0.7260 - direction_inacc: 0.2739 - pred_zero: 0.0000e+00 - direction_acc_pos: 0.3622 - direction_inacc_pos: 0.1368 - direction_acc_neg: 0.3638 - direction_inacc_neg: 0.1371 - val_loss: 0.0891 - val_mae: 0.2827 - val_direction_acc: 0.7118 - val_direction_inacc: 0.2882 - val_pred_zero: 0.0000e+00 - val_direction_acc_pos: 0.3774 - val_direction_inacc_pos: 0.1228 - val_direction_acc_neg: 0.3344 - val_direction_inacc_neg: 0.1654\n",
      "Epoch 4/5\n",
      "3500/3500 [==============================] - 397s 114ms/step - loss: 0.1338 - mae: 0.3685 - direction_acc: 0.7274 - direction_inacc: 0.2726 - pred_zero: 0.0000e+00 - direction_acc_pos: 0.3617 - direction_inacc_pos: 0.1373 - direction_acc_neg: 0.3656 - direction_inacc_neg: 0.1354 - val_loss: 0.0905 - val_mae: 0.2850 - val_direction_acc: 0.7087 - val_direction_inacc: 0.2913 - val_pred_zero: 0.0000e+00 - val_direction_acc_pos: 0.3578 - val_direction_inacc_pos: 0.1423 - val_direction_acc_neg: 0.3508 - val_direction_inacc_neg: 0.1490\n",
      "Epoch 5/5\n",
      "3500/3500 [==============================] - 396s 113ms/step - loss: 0.1320 - mae: 0.3662 - direction_acc: 0.7280 - direction_inacc: 0.2720 - pred_zero: 0.0000e+00 - direction_acc_pos: 0.3625 - direction_inacc_pos: 0.1365 - direction_acc_neg: 0.3655 - direction_inacc_neg: 0.1355 - val_loss: 0.0914 - val_mae: 0.2868 - val_direction_acc: 0.7089 - val_direction_inacc: 0.2911 - val_pred_zero: 4.4784e-06 - val_direction_acc_pos: 0.3523 - val_direction_inacc_pos: 0.1479 - val_direction_acc_neg: 0.3566 - val_direction_inacc_neg: 0.1432\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_ret_noact.compile(loss=keras.losses.Huber(), optimizer=optimizer, metrics=[\"mae\", \n",
    "                                                                                 direction_acc, \n",
    "                                                                                 direction_inacc, \n",
    "                                                                                 pred_zero, \n",
    "                                                                                 direction_acc_pos, \n",
    "                                                                                 direction_inacc_pos,\n",
    "                                                                                 direction_acc_neg,\n",
    "                                                                                 direction_inacc_neg,])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_ret_noact.h5\", save_best_only=True)\n",
    "\n",
    "history = model_ret_noact.fit(ds_train, epochs=5,\n",
    "                       validation_data=ds_valid,\n",
    "                       callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ret_pos = keras.models.load_model(\"model_return_pos.h5\", custom_objects={'GatedActivationUnit' : GatedActivationUnit,\n",
    "                                                                               'direction_acc' : direction_acc,\n",
    "                                                                               'direction_inacc' : direction_inacc,\n",
    "                                                                                'pred_zero' : pred_zero})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ret_neg = keras.models.load_model(\"model_return_neg.h5\", custom_objects={'GatedActivationUnit' : GatedActivationUnit,\n",
    "                                                                               'direction_acc' : direction_acc,\n",
    "                                                                               'direction_inacc' : direction_inacc,\n",
    "                                                                               'pred_zero' : pred_zero})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ret_noact = keras.models.load_model(\"model_ret_noact.h5\", custom_objects={'GatedActivationUnit' : GatedActivationUnit,\n",
    "                                                                                 'direction_acc' : direction_acc,\n",
    "                                                                                 'direction_inacc' : direction_inacc,\n",
    "                                                                                 'pred_zero' : pred_zero,\n",
    "                                                                                 'direction_acc_pos' : direction_acc_pos,\n",
    "                                                                                 'direction_acc_neg' : direction_acc_neg,\n",
    "                                                                                 'direction_inacc_pos' : direction_inacc_pos,\n",
    "                                                                                 'direction_inacc_neg' : direction_inacc_neg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1163/Unknown - 92s 79ms/step - loss: 0.1096 - mae: 0.3191 - direction_acc: 0.3337 - direction_inacc: 0.1240 - pred_zero: 0.5423[0.10958664581061102, 0.31914082, 0.333714, 0.124032676, 0.5422533]\n",
      "   1163/Unknown - 89s 76ms/step - loss: 0.1094 - mae: 0.3187 - direction_acc: 0.3025 - direction_inacc: 0.0997 - pred_zero: 0.5978[0.10943622453104598, 0.31869307, 0.30252668, 0.09966592, 0.5978074]\n",
      "   1163/Unknown - 89s 77ms/step - loss: 0.0888 - mae: 0.2835 - direction_acc: 0.7075 - direction_inacc: 0.2925 - pred_zero: 0.0000e+00 - direction_acc_pos: 0.3865 - direction_inacc_pos: 0.1137 - direction_acc_neg: 0.3210 - direction_inacc_neg: 0.1788[0.0888115835383291, 0.283519, 0.70749587, 0.29249516, 0.0, 0.38649148, 0.113669746, 0.32100442, 0.17882541]\n"
     ]
    }
   ],
   "source": [
    "print(model_ret_pos.evaluate(ds_valid))\n",
    "print(model_ret_neg.evaluate(ds_valid))\n",
    "print(model_ret_noact.evaluate(ds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos = model_ret_pos.predict(ds_valid)\n",
    "pred_neg = model_ret_neg.predict(ds_valid)\n",
    "pred_noact = model_ret_noact.predict(ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos = pred_pos[:, -1, :]\n",
    "pred_neg = pred_neg[:, -1, :]\n",
    "pred_noact = pred_noact[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_pos).to_csv('pred_pos.csv')\n",
    "pd.DataFrame(pred_neg).to_csv('pred_neg.csv')\n",
    "pd.DataFrame(pred_noact).to_csv('pred_noact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos = pd.read_csv('pred_pos.csv', header=0, names = ['ix', 'c_eur', 'c_gbp', 'c_jpy']).iloc[:,1:]\n",
    "pred_neg = pd.read_csv('pred_neg.csv',header=0, names = ['ix', 'c_eur', 'c_gbp', 'c_jpy']).iloc[:,1:]\n",
    "pred_noact = pd.read_csv('pred_noact.csv',header=0, names = ['ix', 'c_eur', 'c_gbp', 'c_jpy']).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.221832</td>\n",
       "      <td>0.202434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74427</th>\n",
       "      <td>0.166318</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.336353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74428</th>\n",
       "      <td>0.129790</td>\n",
       "      <td>1.166341</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74429</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235035</td>\n",
       "      <td>0.637633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74430</th>\n",
       "      <td>0.039457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74431</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74432 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_eur     c_gbp     c_jpy\n",
       "0      0.000000  0.000000  0.658592\n",
       "1      0.164198  0.000000  0.000000\n",
       "2      0.000000  0.000000  0.000000\n",
       "3      0.000000  0.000000  0.000000\n",
       "4      0.221832  0.202434  0.000000\n",
       "...         ...       ...       ...\n",
       "74427  0.166318  0.069800  0.336353\n",
       "74428  0.129790  1.166341  0.000000\n",
       "74429  0.000000  0.235035  0.637633\n",
       "74430  0.039457  0.000000  0.231163\n",
       "74431  0.000000  0.000000  0.000000\n",
       "\n",
       "[74432 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean_log_r</th>\n",
       "      <th>mean_log_r</th>\n",
       "      <th>mean_log_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 23:00:00</th>\n",
       "      <td>-0.204493</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>-1.851031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 23:05:00</th>\n",
       "      <td>0.211720</td>\n",
       "      <td>-0.682056</td>\n",
       "      <td>-0.042275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 23:10:00</th>\n",
       "      <td>0.119111</td>\n",
       "      <td>0.078771</td>\n",
       "      <td>-0.308178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 23:15:00</th>\n",
       "      <td>0.004277</td>\n",
       "      <td>-0.037280</td>\n",
       "      <td>-0.597788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 23:20:00</th>\n",
       "      <td>0.124356</td>\n",
       "      <td>-0.145055</td>\n",
       "      <td>0.165415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:35:00</th>\n",
       "      <td>-0.048386</td>\n",
       "      <td>0.197334</td>\n",
       "      <td>-0.022041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:40:00</th>\n",
       "      <td>-0.000601</td>\n",
       "      <td>1.112390</td>\n",
       "      <td>0.169539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:45:00</th>\n",
       "      <td>-0.182122</td>\n",
       "      <td>1.715093</td>\n",
       "      <td>-0.207541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:50:00</th>\n",
       "      <td>-0.151968</td>\n",
       "      <td>0.194708</td>\n",
       "      <td>0.026822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:55:00</th>\n",
       "      <td>-0.198915</td>\n",
       "      <td>-0.343131</td>\n",
       "      <td>-0.608848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74635 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         c_eur      c_gbp      c_jpy\n",
       "                    mean_log_r mean_log_r mean_log_r\n",
       "ctime                                               \n",
       "2019-01-01 23:00:00  -0.204493  -0.463093  -1.851031\n",
       "2019-01-01 23:05:00   0.211720  -0.682056  -0.042275\n",
       "2019-01-01 23:10:00   0.119111   0.078771  -0.308178\n",
       "2019-01-01 23:15:00   0.004277  -0.037280  -0.597788\n",
       "2019-01-01 23:20:00   0.124356  -0.145055   0.165415\n",
       "...                        ...        ...        ...\n",
       "2019-12-31 21:35:00  -0.048386   0.197334  -0.022041\n",
       "2019-12-31 21:40:00  -0.000601   1.112390   0.169539\n",
       "2019-12-31 21:45:00  -0.182122   1.715093  -0.207541\n",
       "2019-12-31 21:50:00  -0.151968   0.194708   0.026822\n",
       "2019-12-31 21:55:00  -0.198915  -0.343131  -0.608848\n",
       "\n",
       "[74635 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_return_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_test = df_label_return_valid.iloc[144:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_test = df_label_test[:74432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_test.columns = df_label_test.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.152821</td>\n",
       "      <td>-0.202791</td>\n",
       "      <td>-0.179070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.733175</td>\n",
       "      <td>-0.458837</td>\n",
       "      <td>-0.894827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.315369</td>\n",
       "      <td>-0.539606</td>\n",
       "      <td>-0.509547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.236286</td>\n",
       "      <td>-0.354351</td>\n",
       "      <td>-0.556738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.568475</td>\n",
       "      <td>0.805176</td>\n",
       "      <td>0.521231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74427</th>\n",
       "      <td>0.524363</td>\n",
       "      <td>1.498890</td>\n",
       "      <td>0.245461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74428</th>\n",
       "      <td>-0.023553</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>-0.251353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74429</th>\n",
       "      <td>-0.366690</td>\n",
       "      <td>-1.429068</td>\n",
       "      <td>0.418885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74430</th>\n",
       "      <td>-0.287221</td>\n",
       "      <td>-0.649645</td>\n",
       "      <td>-0.137921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74431</th>\n",
       "      <td>-0.463287</td>\n",
       "      <td>-0.039784</td>\n",
       "      <td>-0.060899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74432 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_eur     c_gbp     c_jpy\n",
       "0     -0.152821 -0.202791 -0.179070\n",
       "1     -0.733175 -0.458837 -0.894827\n",
       "2     -1.315369 -0.539606 -0.509547\n",
       "3     -0.236286 -0.354351 -0.556738\n",
       "4      1.568475  0.805176  0.521231\n",
       "...         ...       ...       ...\n",
       "74427  0.524363  1.498890  0.245461\n",
       "74428 -0.023553  0.528620 -0.251353\n",
       "74429 -0.366690 -1.429068  0.418885\n",
       "74430 -0.287221 -0.649645 -0.137921\n",
       "74431 -0.463287 -0.039784 -0.060899\n",
       "\n",
       "[74432 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_test.reset_index(inplace = True)\n",
    "df_label_test = df_label_test.drop(columns=['ctime'])\n",
    "df_label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31903169787425056\n",
      "0.3186375348751795\n",
      "0.28351312171915916\n"
     ]
    }
   ],
   "source": [
    "# test if we are ok:\n",
    "print(df_label_test.sub(pred_pos).abs().mean().mean())\n",
    "print(df_label_test.sub(pred_neg).abs().mean().mean())\n",
    "print(df_label_test.sub(pred_noact).abs().mean().mean())\n",
    "# ok, same as from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_double_act = pd.concat([pred_pos, pred_neg, pred_noact, df_label_test], axis=1, keys=['pos', 'neg', 'noact', 'label'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">pos</th>\n",
       "      <th colspan=\"3\" halign=\"left\">neg</th>\n",
       "      <th colspan=\"3\" halign=\"left\">noact</th>\n",
       "      <th colspan=\"3\" halign=\"left\">label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658592</td>\n",
       "      <td>-0.275718</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.011522</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>0.859337</td>\n",
       "      <td>-0.152821</td>\n",
       "      <td>-0.202791</td>\n",
       "      <td>-0.179070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.104623</td>\n",
       "      <td>-0.647641</td>\n",
       "      <td>-0.184416</td>\n",
       "      <td>-0.352459</td>\n",
       "      <td>-0.597647</td>\n",
       "      <td>-0.733175</td>\n",
       "      <td>-0.458837</td>\n",
       "      <td>-0.894827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.848652</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.307110</td>\n",
       "      <td>-0.931917</td>\n",
       "      <td>-0.513463</td>\n",
       "      <td>-0.426679</td>\n",
       "      <td>-1.315369</td>\n",
       "      <td>-0.539606</td>\n",
       "      <td>-0.509547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.720256</td>\n",
       "      <td>-0.654472</td>\n",
       "      <td>-0.271369</td>\n",
       "      <td>-0.719075</td>\n",
       "      <td>-0.606441</td>\n",
       "      <td>-0.029457</td>\n",
       "      <td>-0.236286</td>\n",
       "      <td>-0.354351</td>\n",
       "      <td>-0.556738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.221832</td>\n",
       "      <td>0.202434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.270350</td>\n",
       "      <td>0.662746</td>\n",
       "      <td>0.375412</td>\n",
       "      <td>-0.283819</td>\n",
       "      <td>1.568475</td>\n",
       "      <td>0.805176</td>\n",
       "      <td>0.521231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74427</th>\n",
       "      <td>0.166318</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.336353</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.063328</td>\n",
       "      <td>-0.109615</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>0.524363</td>\n",
       "      <td>1.498890</td>\n",
       "      <td>0.245461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74428</th>\n",
       "      <td>0.129790</td>\n",
       "      <td>1.166341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.042822</td>\n",
       "      <td>0.418199</td>\n",
       "      <td>0.857505</td>\n",
       "      <td>0.208144</td>\n",
       "      <td>-0.023553</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>-0.251353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74429</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235035</td>\n",
       "      <td>0.637633</td>\n",
       "      <td>-0.029545</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>0.343883</td>\n",
       "      <td>0.279920</td>\n",
       "      <td>-0.366690</td>\n",
       "      <td>-1.429068</td>\n",
       "      <td>0.418885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74430</th>\n",
       "      <td>0.039457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231163</td>\n",
       "      <td>-0.011902</td>\n",
       "      <td>-0.179632</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.115993</td>\n",
       "      <td>-0.079356</td>\n",
       "      <td>0.183840</td>\n",
       "      <td>-0.287221</td>\n",
       "      <td>-0.649645</td>\n",
       "      <td>-0.137921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74431</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.237564</td>\n",
       "      <td>-0.174447</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.128946</td>\n",
       "      <td>-0.094197</td>\n",
       "      <td>-0.076094</td>\n",
       "      <td>-0.463287</td>\n",
       "      <td>-0.039784</td>\n",
       "      <td>-0.060899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74432 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos                           neg                         noact  \\\n",
       "          c_eur     c_gbp     c_jpy     c_eur     c_gbp     c_jpy     c_eur   \n",
       "0      0.000000  0.000000  0.658592 -0.275718 -0.000000 -0.000000 -0.011522   \n",
       "1      0.164198  0.000000  0.000000 -0.000000 -0.104623 -0.647641 -0.184416   \n",
       "2      0.000000  0.000000  0.000000 -0.848652 -0.000000 -0.307110 -0.931917   \n",
       "3      0.000000  0.000000  0.000000 -0.720256 -0.654472 -0.271369 -0.719075   \n",
       "4      0.221832  0.202434  0.000000 -0.000000 -0.000000 -0.270350  0.662746   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "74427  0.166318  0.069800  0.336353 -0.000000 -0.000000 -0.000000 -0.063328   \n",
       "74428  0.129790  1.166341  0.000000 -0.000000 -0.000000 -0.042822  0.418199   \n",
       "74429  0.000000  0.235035  0.637633 -0.029545 -0.000000 -0.000000  0.038537   \n",
       "74430  0.039457  0.000000  0.231163 -0.011902 -0.179632 -0.000000  0.115993   \n",
       "74431  0.000000  0.000000  0.000000 -0.237564 -0.174447 -0.000000 -0.128946   \n",
       "\n",
       "                              label                      \n",
       "          c_gbp     c_jpy     c_eur     c_gbp     c_jpy  \n",
       "0      0.033756  0.859337 -0.152821 -0.202791 -0.179070  \n",
       "1     -0.352459 -0.597647 -0.733175 -0.458837 -0.894827  \n",
       "2     -0.513463 -0.426679 -1.315369 -0.539606 -0.509547  \n",
       "3     -0.606441 -0.029457 -0.236286 -0.354351 -0.556738  \n",
       "4      0.375412 -0.283819  1.568475  0.805176  0.521231  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "74427 -0.109615 -0.010298  0.524363  1.498890  0.245461  \n",
       "74428  0.857505  0.208144 -0.023553  0.528620 -0.251353  \n",
       "74429  0.343883  0.279920 -0.366690 -1.429068  0.418885  \n",
       "74430 -0.079356  0.183840 -0.287221 -0.649645 -0.137921  \n",
       "74431 -0.094197 -0.076094 -0.463287 -0.039784 -0.060899  \n",
       "\n",
       "[74432 rows x 12 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_double_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_filter(row):\n",
    "    if(row[0] != 0.0) and (row[1] != 0.0):\n",
    "        val = 0.0\n",
    "    elif(row[0] > 0):\n",
    "        val = row[0]\n",
    "    else:\n",
    "        val = row[1]   \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_double_act[('dbl', 'c_eur')] = pred_double_act[[('pos', 'c_eur'), ('neg', 'c_eur')]].apply(prediction_filter, axis=1)\n",
    "pred_double_act[('dbl', 'c_gbp')] = pred_double_act[[('pos', 'c_gbp'), ('neg', 'c_gbp')]].apply(prediction_filter, axis=1)\n",
    "pred_double_act[('dbl', 'c_jpy')] = pred_double_act[[('pos', 'c_jpy'), ('neg', 'c_jpy')]].apply(prediction_filter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">pos</th>\n",
       "      <th colspan=\"3\" halign=\"left\">neg</th>\n",
       "      <th colspan=\"3\" halign=\"left\">noact</th>\n",
       "      <th colspan=\"3\" halign=\"left\">label</th>\n",
       "      <th colspan=\"3\" halign=\"left\">dbl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658592</td>\n",
       "      <td>-0.275718</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.011522</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>0.859337</td>\n",
       "      <td>-0.152821</td>\n",
       "      <td>-0.202791</td>\n",
       "      <td>-0.179070</td>\n",
       "      <td>-0.275718</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.658592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.104623</td>\n",
       "      <td>-0.647641</td>\n",
       "      <td>-0.184416</td>\n",
       "      <td>-0.352459</td>\n",
       "      <td>-0.597647</td>\n",
       "      <td>-0.733175</td>\n",
       "      <td>-0.458837</td>\n",
       "      <td>-0.894827</td>\n",
       "      <td>0.164198</td>\n",
       "      <td>-0.104623</td>\n",
       "      <td>-0.647641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.848652</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.307110</td>\n",
       "      <td>-0.931917</td>\n",
       "      <td>-0.513463</td>\n",
       "      <td>-0.426679</td>\n",
       "      <td>-1.315369</td>\n",
       "      <td>-0.539606</td>\n",
       "      <td>-0.509547</td>\n",
       "      <td>-0.848652</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.307110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.720256</td>\n",
       "      <td>-0.654472</td>\n",
       "      <td>-0.271369</td>\n",
       "      <td>-0.719075</td>\n",
       "      <td>-0.606441</td>\n",
       "      <td>-0.029457</td>\n",
       "      <td>-0.236286</td>\n",
       "      <td>-0.354351</td>\n",
       "      <td>-0.556738</td>\n",
       "      <td>-0.720256</td>\n",
       "      <td>-0.654472</td>\n",
       "      <td>-0.271369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.221832</td>\n",
       "      <td>0.202434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.270350</td>\n",
       "      <td>0.662746</td>\n",
       "      <td>0.375412</td>\n",
       "      <td>-0.283819</td>\n",
       "      <td>1.568475</td>\n",
       "      <td>0.805176</td>\n",
       "      <td>0.521231</td>\n",
       "      <td>0.221832</td>\n",
       "      <td>0.202434</td>\n",
       "      <td>-0.270350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74427</th>\n",
       "      <td>0.166318</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.336353</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.063328</td>\n",
       "      <td>-0.109615</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>0.524363</td>\n",
       "      <td>1.498890</td>\n",
       "      <td>0.245461</td>\n",
       "      <td>0.166318</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.336353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74428</th>\n",
       "      <td>0.129790</td>\n",
       "      <td>1.166341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.042822</td>\n",
       "      <td>0.418199</td>\n",
       "      <td>0.857505</td>\n",
       "      <td>0.208144</td>\n",
       "      <td>-0.023553</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>-0.251353</td>\n",
       "      <td>0.129790</td>\n",
       "      <td>1.166341</td>\n",
       "      <td>-0.042822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74429</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235035</td>\n",
       "      <td>0.637633</td>\n",
       "      <td>-0.029545</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>0.343883</td>\n",
       "      <td>0.279920</td>\n",
       "      <td>-0.366690</td>\n",
       "      <td>-1.429068</td>\n",
       "      <td>0.418885</td>\n",
       "      <td>-0.029545</td>\n",
       "      <td>0.235035</td>\n",
       "      <td>0.637633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74430</th>\n",
       "      <td>0.039457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231163</td>\n",
       "      <td>-0.011902</td>\n",
       "      <td>-0.179632</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.115993</td>\n",
       "      <td>-0.079356</td>\n",
       "      <td>0.183840</td>\n",
       "      <td>-0.287221</td>\n",
       "      <td>-0.649645</td>\n",
       "      <td>-0.137921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.179632</td>\n",
       "      <td>0.231163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74431</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.237564</td>\n",
       "      <td>-0.174447</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.128946</td>\n",
       "      <td>-0.094197</td>\n",
       "      <td>-0.076094</td>\n",
       "      <td>-0.463287</td>\n",
       "      <td>-0.039784</td>\n",
       "      <td>-0.060899</td>\n",
       "      <td>-0.237564</td>\n",
       "      <td>-0.174447</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74432 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos                           neg                         noact  \\\n",
       "          c_eur     c_gbp     c_jpy     c_eur     c_gbp     c_jpy     c_eur   \n",
       "0      0.000000  0.000000  0.658592 -0.275718 -0.000000 -0.000000 -0.011522   \n",
       "1      0.164198  0.000000  0.000000 -0.000000 -0.104623 -0.647641 -0.184416   \n",
       "2      0.000000  0.000000  0.000000 -0.848652 -0.000000 -0.307110 -0.931917   \n",
       "3      0.000000  0.000000  0.000000 -0.720256 -0.654472 -0.271369 -0.719075   \n",
       "4      0.221832  0.202434  0.000000 -0.000000 -0.000000 -0.270350  0.662746   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "74427  0.166318  0.069800  0.336353 -0.000000 -0.000000 -0.000000 -0.063328   \n",
       "74428  0.129790  1.166341  0.000000 -0.000000 -0.000000 -0.042822  0.418199   \n",
       "74429  0.000000  0.235035  0.637633 -0.029545 -0.000000 -0.000000  0.038537   \n",
       "74430  0.039457  0.000000  0.231163 -0.011902 -0.179632 -0.000000  0.115993   \n",
       "74431  0.000000  0.000000  0.000000 -0.237564 -0.174447 -0.000000 -0.128946   \n",
       "\n",
       "                              label                           dbl            \\\n",
       "          c_gbp     c_jpy     c_eur     c_gbp     c_jpy     c_eur     c_gbp   \n",
       "0      0.033756  0.859337 -0.152821 -0.202791 -0.179070 -0.275718 -0.000000   \n",
       "1     -0.352459 -0.597647 -0.733175 -0.458837 -0.894827  0.164198 -0.104623   \n",
       "2     -0.513463 -0.426679 -1.315369 -0.539606 -0.509547 -0.848652 -0.000000   \n",
       "3     -0.606441 -0.029457 -0.236286 -0.354351 -0.556738 -0.720256 -0.654472   \n",
       "4      0.375412 -0.283819  1.568475  0.805176  0.521231  0.221832  0.202434   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "74427 -0.109615 -0.010298  0.524363  1.498890  0.245461  0.166318  0.069800   \n",
       "74428  0.857505  0.208144 -0.023553  0.528620 -0.251353  0.129790  1.166341   \n",
       "74429  0.343883  0.279920 -0.366690 -1.429068  0.418885 -0.029545  0.235035   \n",
       "74430 -0.079356  0.183840 -0.287221 -0.649645 -0.137921  0.000000 -0.179632   \n",
       "74431 -0.094197 -0.076094 -0.463287 -0.039784 -0.060899 -0.237564 -0.174447   \n",
       "\n",
       "                 \n",
       "          c_jpy  \n",
       "0      0.658592  \n",
       "1     -0.647641  \n",
       "2     -0.307110  \n",
       "3     -0.271369  \n",
       "4     -0.270350  \n",
       "...         ...  \n",
       "74427  0.336353  \n",
       "74428 -0.042822  \n",
       "74429  0.637633  \n",
       "74430  0.231163  \n",
       "74431 -0.000000  \n",
       "\n",
       "[74432 rows x 15 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_double_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28218349869109094\n"
     ]
    }
   ],
   "source": [
    "print(df_label_test.sub(pred_double_act['dbl']).abs().mean().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_pos = (df_label_test.multiply(pred_double_act['pos'])>0.0).mean().mean()\n",
    "acc_neg = (df_label_test.multiply(pred_double_act['neg'])>0.0).mean().mean()\n",
    "acc_noact = (df_label_test.multiply(pred_double_act['noact'])>0.0).mean().mean()\n",
    "acc_dbl = (df_label_test.multiply(pred_double_act['dbl'])>0.0).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc_pos = (df_label_test.multiply(pred_double_act['pos'])<0.0).mean().mean()\n",
    "inacc_neg = (df_label_test.multiply(pred_double_act['neg'])<0.0).mean().mean()\n",
    "inacc_noact = (df_label_test.multiply(pred_double_act['noact'])<0.0).mean().mean()\n",
    "inacc_dbl = (df_label_test.multiply(pred_double_act['dbl'])<0.0).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3337139939810834\n",
      "0.30252669102894814\n",
      "0.7074958799082832\n",
      "0.6155954428202924\n"
     ]
    }
   ],
   "source": [
    "print(acc_pos)\n",
    "print(acc_neg)\n",
    "print(acc_noact)\n",
    "print(acc_dbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12403267411865863\n",
      "0.0996659143020923\n",
      "0.2924951633705933\n",
      "0.20305334623101176\n"
     ]
    }
   ],
   "source": [
    "print(inacc_pos)\n",
    "print(inacc_neg)\n",
    "print(inacc_noact)\n",
    "print(inacc_dbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.690532928942808\n",
      "3.035407773534037\n",
      "2.4188293295362335\n",
      "3.031693169537505\n"
     ]
    }
   ],
   "source": [
    "print(acc_pos/inacc_pos)\n",
    "print(acc_neg/inacc_neg)\n",
    "print(acc_noact/inacc_noact)\n",
    "print(acc_dbl/inacc_dbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
