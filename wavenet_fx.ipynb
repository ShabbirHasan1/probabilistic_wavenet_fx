{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 4th root for embedding: https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combined forex and economic news data\n",
    "df = pd.read_csv('fx_with_news.csv', header=[0,1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">c_eur</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">after_counter_ohe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>bar_len</th>\n",
       "      <th>bar_spearman</th>\n",
       "      <th>bar_log_r</th>\n",
       "      <th>first_r</th>\n",
       "      <th>max_r</th>\n",
       "      <th>min_r</th>\n",
       "      <th>last_r</th>\n",
       "      <th>bar_quantile_25_r</th>\n",
       "      <th>...</th>\n",
       "      <th>_united states nondefense capital goods orders ex aircraft</th>\n",
       "      <th>_united states nonfarm payrolls</th>\n",
       "      <th>_united states retail sales control group</th>\n",
       "      <th>_united states retail sales ex autos mom</th>\n",
       "      <th>_united states retail sales mom</th>\n",
       "      <th>_united states reutersmichigan consumer sentiment index</th>\n",
       "      <th>_united states trade balance</th>\n",
       "      <th>_united states unemployment rate</th>\n",
       "      <th>_usd event</th>\n",
       "      <th>_usd speech</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:00:00</th>\n",
       "      <td>1.088</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.73730</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:05:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-0.18100</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:10:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-0.46040</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:15:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.28220</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:20:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-0.04312</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:35:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.80100</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972569</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:40:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.14160</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:45:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.61300</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:50:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-0.91260</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:55:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.07510</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298829 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     c_eur                                                     \\\n",
       "                      mean       std bar_len bar_spearman bar_log_r   first_r   \n",
       "ctime                                                                           \n",
       "2016-01-03 22:00:00  1.088  0.000015    28.0     -0.73730 -0.000037  0.000030   \n",
       "2016-01-03 22:05:00  1.087  0.000049   155.0     -0.18100 -0.000230  0.000081   \n",
       "2016-01-03 22:10:00  1.087  0.000105   138.0     -0.46040 -0.000248  0.000202   \n",
       "2016-01-03 22:15:00  1.087  0.000043   125.0      0.28220 -0.000028 -0.000007   \n",
       "2016-01-03 22:20:00  1.087  0.000148   115.0     -0.04312 -0.000120 -0.000144   \n",
       "...                    ...       ...     ...          ...       ...       ...   \n",
       "2019-12-31 21:35:00  1.121  0.000036    62.0     -0.80100 -0.000080  0.000062   \n",
       "2019-12-31 21:40:00  1.121  0.000028    41.0     -0.14160 -0.000009 -0.000027   \n",
       "2019-12-31 21:45:00  1.121  0.000046   108.0      0.61300 -0.000018  0.000029   \n",
       "2019-12-31 21:50:00  1.121  0.000046    97.0     -0.91260 -0.000143  0.000056   \n",
       "2019-12-31 21:55:00  1.121  0.000131    91.0      0.07510  0.000294 -0.000033   \n",
       "\n",
       "                                                                     ...  \\\n",
       "                        max_r     min_r    last_r bar_quantile_25_r  ...   \n",
       "ctime                                                                ...   \n",
       "2016-01-03 22:00:00  0.000030 -0.000016 -0.000007         -0.000009  ...   \n",
       "2016-01-03 22:05:00  0.000081 -0.000149 -0.000149         -0.000029  ...   \n",
       "2016-01-03 22:10:00  0.000202 -0.000147 -0.000046         -0.000064  ...   \n",
       "2016-01-03 22:15:00  0.000057 -0.000108 -0.000035         -0.000007  ...   \n",
       "2016-01-03 22:20:00  0.000224 -0.000264 -0.000264         -0.000126  ...   \n",
       "...                       ...       ...       ...               ...  ...   \n",
       "2019-12-31 21:35:00  0.000062 -0.000036 -0.000018         -0.000027  ...   \n",
       "2019-12-31 21:40:00  0.000035 -0.000054 -0.000036         -0.000018  ...   \n",
       "2019-12-31 21:45:00  0.000047 -0.000096  0.000011         -0.000024  ...   \n",
       "2019-12-31 21:50:00  0.000092 -0.000122 -0.000086         -0.000015  ...   \n",
       "2019-12-31 21:55:00  0.000261 -0.000122  0.000261         -0.000078  ...   \n",
       "\n",
       "                                                             after_counter_ohe  \\\n",
       "                    _united states nondefense capital goods orders ex aircraft   \n",
       "ctime                                                                            \n",
       "2016-01-03 22:00:00                                           0.000000           \n",
       "2016-01-03 22:05:00                                           0.000000           \n",
       "2016-01-03 22:10:00                                           0.000000           \n",
       "2016-01-03 22:15:00                                           0.000000           \n",
       "2016-01-03 22:20:00                                           0.000000           \n",
       "...                                                                ...           \n",
       "2019-12-31 21:35:00                                           0.429514           \n",
       "2019-12-31 21:40:00                                           0.429167           \n",
       "2019-12-31 21:45:00                                           0.428819           \n",
       "2019-12-31 21:50:00                                           0.428472           \n",
       "2019-12-31 21:55:00                                           0.428125           \n",
       "\n",
       "                                                     \\\n",
       "                    _united states nonfarm payrolls   \n",
       "ctime                                                 \n",
       "2016-01-03 22:00:00                             0.0   \n",
       "2016-01-03 22:05:00                             0.0   \n",
       "2016-01-03 22:10:00                             0.0   \n",
       "2016-01-03 22:15:00                             0.0   \n",
       "2016-01-03 22:20:00                             0.0   \n",
       "...                                             ...   \n",
       "2019-12-31 21:35:00                             0.0   \n",
       "2019-12-31 21:40:00                             0.0   \n",
       "2019-12-31 21:45:00                             0.0   \n",
       "2019-12-31 21:50:00                             0.0   \n",
       "2019-12-31 21:55:00                             0.0   \n",
       "\n",
       "                                                               \\\n",
       "                    _united states retail sales control group   \n",
       "ctime                                                           \n",
       "2016-01-03 22:00:00                                       0.0   \n",
       "2016-01-03 22:05:00                                       0.0   \n",
       "2016-01-03 22:10:00                                       0.0   \n",
       "2016-01-03 22:15:00                                       0.0   \n",
       "2016-01-03 22:20:00                                       0.0   \n",
       "...                                                       ...   \n",
       "2019-12-31 21:35:00                                       0.0   \n",
       "2019-12-31 21:40:00                                       0.0   \n",
       "2019-12-31 21:45:00                                       0.0   \n",
       "2019-12-31 21:50:00                                       0.0   \n",
       "2019-12-31 21:55:00                                       0.0   \n",
       "\n",
       "                                                              \\\n",
       "                    _united states retail sales ex autos mom   \n",
       "ctime                                                          \n",
       "2016-01-03 22:00:00                                      0.0   \n",
       "2016-01-03 22:05:00                                      0.0   \n",
       "2016-01-03 22:10:00                                      0.0   \n",
       "2016-01-03 22:15:00                                      0.0   \n",
       "2016-01-03 22:20:00                                      0.0   \n",
       "...                                                      ...   \n",
       "2019-12-31 21:35:00                                      0.0   \n",
       "2019-12-31 21:40:00                                      0.0   \n",
       "2019-12-31 21:45:00                                      0.0   \n",
       "2019-12-31 21:50:00                                      0.0   \n",
       "2019-12-31 21:55:00                                      0.0   \n",
       "\n",
       "                                                     \\\n",
       "                    _united states retail sales mom   \n",
       "ctime                                                 \n",
       "2016-01-03 22:00:00                             0.0   \n",
       "2016-01-03 22:05:00                             0.0   \n",
       "2016-01-03 22:10:00                             0.0   \n",
       "2016-01-03 22:15:00                             0.0   \n",
       "2016-01-03 22:20:00                             0.0   \n",
       "...                                             ...   \n",
       "2019-12-31 21:35:00                             0.0   \n",
       "2019-12-31 21:40:00                             0.0   \n",
       "2019-12-31 21:45:00                             0.0   \n",
       "2019-12-31 21:50:00                             0.0   \n",
       "2019-12-31 21:55:00                             0.0   \n",
       "\n",
       "                                                                             \\\n",
       "                    _united states reutersmichigan consumer sentiment index   \n",
       "ctime                                                                         \n",
       "2016-01-03 22:00:00                                                0.0        \n",
       "2016-01-03 22:05:00                                                0.0        \n",
       "2016-01-03 22:10:00                                                0.0        \n",
       "2016-01-03 22:15:00                                                0.0        \n",
       "2016-01-03 22:20:00                                                0.0        \n",
       "...                                                                ...        \n",
       "2019-12-31 21:35:00                                                0.0        \n",
       "2019-12-31 21:40:00                                                0.0        \n",
       "2019-12-31 21:45:00                                                0.0        \n",
       "2019-12-31 21:50:00                                                0.0        \n",
       "2019-12-31 21:55:00                                                0.0        \n",
       "\n",
       "                                                  \\\n",
       "                    _united states trade balance   \n",
       "ctime                                              \n",
       "2016-01-03 22:00:00                          0.0   \n",
       "2016-01-03 22:05:00                          0.0   \n",
       "2016-01-03 22:10:00                          0.0   \n",
       "2016-01-03 22:15:00                          0.0   \n",
       "2016-01-03 22:20:00                          0.0   \n",
       "...                                          ...   \n",
       "2019-12-31 21:35:00                          0.0   \n",
       "2019-12-31 21:40:00                          0.0   \n",
       "2019-12-31 21:45:00                          0.0   \n",
       "2019-12-31 21:50:00                          0.0   \n",
       "2019-12-31 21:55:00                          0.0   \n",
       "\n",
       "                                                                             \n",
       "                    _united states unemployment rate _usd event _usd speech  \n",
       "ctime                                                                        \n",
       "2016-01-03 22:00:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:05:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:10:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:15:00                              0.0   0.000000         0.0  \n",
       "2016-01-03 22:20:00                              0.0   0.000000         0.0  \n",
       "...                                              ...        ...         ...  \n",
       "2019-12-31 21:35:00                              0.0   0.972569         0.0  \n",
       "2019-12-31 21:40:00                              0.0   0.972222         0.0  \n",
       "2019-12-31 21:45:00                              0.0   0.971875         0.0  \n",
       "2019-12-31 21:50:00                              0.0   0.971528         0.0  \n",
       "2019-12-31 21:55:00                              0.0   0.971181         0.0  \n",
       "\n",
       "[298829 rows x 459 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "TOP COLUMN:  c_eur\n",
      "SUBCOLUMNS:  11\n",
      "['mean', 'std', 'bar_len', 'bar_spearman', 'bar_log_r', 'first_r', 'max_r', 'min_r', 'last_r', 'bar_quantile_25_r', 'bar_quantile_75_r']\n",
      "----------------------------------\n",
      "TOP COLUMN:  c_gbp\n",
      "SUBCOLUMNS:  11\n",
      "['mean', 'std', 'bar_len', 'bar_spearman', 'bar_log_r', 'first_r', 'max_r', 'min_r', 'last_r', 'bar_quantile_25_r', 'bar_quantile_75_r']\n",
      "----------------------------------\n",
      "TOP COLUMN:  c_jpy\n",
      "SUBCOLUMNS:  11\n",
      "['mean', 'std', 'bar_len', 'bar_spearman', 'bar_log_r', 'first_r', 'max_r', 'min_r', 'last_r', 'bar_quantile_25_r', 'bar_quantile_75_r']\n",
      "----------------------------------\n",
      "TOP COLUMN:  month\n",
      "SUBCOLUMNS:  12\n",
      "['_1', '_2', '_3', '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11', '_12']\n",
      "----------------------------------\n",
      "TOP COLUMN:  dow\n",
      "SUBCOLUMNS:  6\n",
      "['_0', '_1', '_2', '_3', '_4', '_6']\n",
      "----------------------------------\n",
      "TOP COLUMN:  hour\n",
      "SUBCOLUMNS:  24\n",
      "['_0', '_1', '_2', '_3', '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11', '_12', '_13', '_14', '_15', '_16', '_17', '_18', '_19', '_20', '_21', '_22', '_23']\n",
      "----------------------------------\n",
      "TOP COLUMN:  event_cur\n",
      "SUBCOLUMNS:  4\n",
      "['_EUR', '_GBP', '_JPY', '_USD']\n",
      "----------------------------------\n",
      "TOP COLUMN:  event_exist\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  actual_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  surprise_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  change_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n",
      "----------------------------------\n",
      "TOP COLUMN:  after_counter_ohe\n",
      "SUBCOLUMNS:  76\n",
      "['_eur event', '_eur speech', '_european monetary union consumer price index  core yoy', '_european monetary union consumer price index yoy', '_european monetary union ecb deposit rate decision', '_european monetary union ecb interest rate decision', '_european monetary union gross domestic product sa qoq', '_european monetary union gross domestic product sa yoy', '_european monetary union markit pmi composite', '_france markit manufacturing pmi', '_gbp event', '_gbp speech', '_germany gross domestic product qoq', '_germany harmonised index of consumer prices yoy', '_germany harmonized index of consumer prices yoy', '_germany markit manufacturing pmi', '_germany unemployment change', '_germany unemployment rate sa', '_germany zew survey  economic sentiment', '_japan boj interest rate decision', '_japan current account nsa', '_japan gross domestic product qoq', '_japan tokyo cpi ex fresh food yoy', '_jpy event', '_jpy speech', '_united kingdom average earnings excluding bonus 3moyr', '_united kingdom average earnings including bonus 3moyr', '_united kingdom boe asset purchase facility', '_united kingdom boe interest rate decision', '_united kingdom boe mpc vote cut', '_united kingdom boe mpc vote hike', '_united kingdom boe mpc vote unchanged', '_united kingdom consumer inflation expectations', '_united kingdom consumer price index yoy', '_united kingdom core consumer price index yoy', '_united kingdom gross domestic product mom', '_united kingdom gross domestic product qoq', '_united kingdom ilo unemployment rate 3m', '_united kingdom niesr gdp estimate 3m', '_united states adp employment change', '_united states average hourly earnings yoy', '_united states building permits change', '_united states building permits mom', '_united states consumer confidence', '_united states consumer price index ex food  energy mom', '_united states consumer price index ex food  energy yoy', '_united states consumer price index yoy', '_united states core personal consumption expenditure  price index mom', '_united states core personal consumption expenditure  price index yoy', '_united states core personal consumption expenditures qoq', '_united states durable goods orders', '_united states durable goods orders ex defense', '_united states durable goods orders ex transportation', '_united states existing home sales mom', '_united states fed interest rate decision', '_united states goods trade balance', '_united states gross domestic product annualized', '_united states gross domestic product price index', '_united states initial jobless claims', '_united states initial jobless claims 4week average', '_united states ism manufacturing pmi', '_united states ism nonmanufacturing pmi', '_united states ism prices paid', '_united states jolts job openings', '_united states michigan consumer sentiment index', '_united states new home sales mom', '_united states nondefense capital goods orders ex aircraft', '_united states nonfarm payrolls', '_united states retail sales control group', '_united states retail sales ex autos mom', '_united states retail sales mom', '_united states reutersmichigan consumer sentiment index', '_united states trade balance', '_united states unemployment rate', '_usd event', '_usd speech']\n"
     ]
    }
   ],
   "source": [
    "# column hierarchy\n",
    "for top in list(df.columns.get_level_values(0).unique()):\n",
    "    print('----------------------------------')\n",
    "    print('TOP COLUMN: ', top)\n",
    "    print('SUBCOLUMNS: ', len(df[top].columns))\n",
    "    print(list(df[top].columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c_eur',\n",
       " 'c_gbp',\n",
       " 'c_jpy',\n",
       " 'month',\n",
       " 'dow',\n",
       " 'hour',\n",
       " 'event_cur',\n",
       " 'event_exist',\n",
       " 'actual_ohe',\n",
       " 'surprise_ohe',\n",
       " 'change_ohe',\n",
       " 'after_counter_ohe']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_level = list(df.columns.get_level_values(0).unique())\n",
    "top_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use 2016-2018 as training data, and 2019 as validation and test data\n",
    "# problem: we have events that occure only in 2019\n",
    "# we can't normalize/standardize/scale them based on 2016-2018 data\n",
    "# we could move them to the '_(currency) event' columns, \n",
    "# but there is only a few, so here I will delete them\n",
    "\n",
    "# have we all event type in 2016-2018 yers?\n",
    "df['event_exist'].loc['2016':'2019'].any().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_european monetary union markit pmi composite',\n",
       " '_germany zew survey  economic sentiment',\n",
       " '_japan gross domestic product qoq',\n",
       " '_united states consumer price index ex food  energy mom',\n",
       " '_united states initial jobless claims 4week average',\n",
       " '_united states nondefense capital goods orders ex aircraft']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find events occuring only in 2019\n",
    "event_before_19 = df['event_exist'].loc['2016':'2019'].any()\n",
    "event_only_19 = list(event_before_19[event_before_19==False].index)\n",
    "event_only_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop events only occuring in 2019\n",
    "df.drop(event_only_19, axis=1, level=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have we all event type in 2016-2018 yers?\n",
    "df['event_exist'].loc['2016':'2019'].any().all()\n",
    "#ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:00:00</th>\n",
       "      <td>1.088</td>\n",
       "      <td>1.474</td>\n",
       "      <td>0.8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:05:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>1.475</td>\n",
       "      <td>0.8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:10:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>1.475</td>\n",
       "      <td>0.8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:15:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>1.475</td>\n",
       "      <td>0.8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:20:00</th>\n",
       "      <td>1.087</td>\n",
       "      <td>1.475</td>\n",
       "      <td>0.8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:35:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>1.325</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:40:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>1.325</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:45:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:50:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:55:00</th>\n",
       "      <td>1.121</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     c_eur  c_gbp   c_jpy\n",
       "                      mean   mean    mean\n",
       "ctime                                    \n",
       "2016-01-03 22:00:00  1.088  1.474  0.8315\n",
       "2016-01-03 22:05:00  1.087  1.475  0.8315\n",
       "2016-01-03 22:10:00  1.087  1.475  0.8315\n",
       "2016-01-03 22:15:00  1.087  1.475  0.8315\n",
       "2016-01-03 22:20:00  1.087  1.475  0.8315\n",
       "...                    ...    ...     ...\n",
       "2019-12-31 21:35:00  1.121  1.325  0.9204\n",
       "2019-12-31 21:40:00  1.121  1.325  0.9204\n",
       "2019-12-31 21:45:00  1.121  1.326  0.9204\n",
       "2019-12-31 21:50:00  1.121  1.326  0.9204\n",
       "2019-12-31 21:55:00  1.121  1.326  0.9204\n",
       "\n",
       "[298829 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label is unstandardized\n",
    "# mean of a bar is less noisy than open or close, probably easier to recognize patterns\n",
    "df_label = df.xs('mean', axis=1, level=1, drop_level=False)\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use only train and validation\n",
    "# Standardizing and normalizing shifts the dataset, where +- sign can be important. Later the model will adjust this by the biases,\n",
    "# but the information is lost. It could improve the performance if we make a new feature for + and - numbers, but here I don't want to make more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = ['c_eur', 'c_gbp', 'c_jpy']\n",
    "# spearman doesn't need standardization\n",
    "c_single_features = ['mean', 'std', 'bar_len']\n",
    "\n",
    "# standardize features based on data up to 2019-01-01 00:00\n",
    "for cur in c_list:\n",
    "    for feature in c_single_features:\n",
    "        df.loc[:,(cur, feature)] = (df[cur, feature] - df[cur, feature].loc['2016':'2019'].mean())/df[cur, feature].loc['2016':'2019'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar_log_r            1756.304442\n",
      "first_r              1079.158825\n",
      "max_r                1680.076339\n",
      "min_r                1686.788351\n",
      "last_r                960.659008\n",
      "bar_quantile_25_r     647.481262\n",
      "bar_quantile_75_r     647.172419\n",
      "dtype: float64\n",
      "bar_log_r               8.381825\n",
      "first_r                -0.841197\n",
      "max_r                1680.076339\n",
      "min_r               -1686.788351\n",
      "last_r                  7.541522\n",
      "bar_quantile_25_r    -647.041006\n",
      "bar_quantile_75_r     646.659303\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "c_related_features = ['bar_log_r','first_r','max_r','min_r','last_r','bar_quantile_25_r','bar_quantile_75_r']\n",
    "# these are related feature, we can think of them as one feature with subfeatures\n",
    "# they are on similar scale \n",
    "# and the pairs on the other side of the mean (like max_r and min_r) are almost symmetric\n",
    "# to preserve the signs we don't subtract the mean, only divide by the std\n",
    "# this way we preserve their relative size\n",
    "# *10000000 is only for easier comparison\n",
    "print(df['c_eur'][c_related_features].abs().mean()*10000000)\n",
    "print(df['c_eur'][c_related_features].mean()*10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_std = df[cur, 'bar_log_r'].loc['2016':'2019'].std()\n",
    "\n",
    "for cur in c_list:\n",
    "    for feature in c_related_features:\n",
    "        df.loc[:,(cur, feature)] = (df[cur, feature])/related_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar_log_r            0.493106\n",
      "first_r              0.302988\n",
      "max_r                0.471704\n",
      "min_r                0.473588\n",
      "last_r               0.269718\n",
      "bar_quantile_25_r    0.181789\n",
      "bar_quantile_75_r    0.181702\n",
      "dtype: float64\n",
      "bar_log_r            0.002353\n",
      "first_r             -0.000236\n",
      "max_r                0.471704\n",
      "min_r               -0.473588\n",
      "last_r               0.002117\n",
      "bar_quantile_25_r   -0.181665\n",
      "bar_quantile_75_r    0.181558\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ok, these features remained on similar scale, but the other features as well\n",
    "print(df['c_eur'][c_related_features].abs().mean())\n",
    "print(df['c_eur'][c_related_features].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_EUR    2.000000\n",
       "_GBP    2.828427\n",
       "_JPY    1.732051\n",
       "_USD    3.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'event_cur' is on similar scale, we don't touch (normalization would be better than standardization)\n",
    "df['event_cur'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should consider every event type alone, but there are 76 event types, so just normalize\n",
    "df['actual_ohe'] = (df['actual_ohe'] - df['actual_ohe'].loc['2016':'2019'].min())/(df['actual_ohe'].loc['2016':'2019'].max() - df['actual_ohe'].loc['2016':'2019'].min())\n",
    "# where max-min == 0 we get NaN, fill with 0\n",
    "df['actual_ohe'] = df['actual_ohe'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing with the max of absolute values keeps the signs\n",
    "df['surprise_ohe'] = df['surprise_ohe']/df['surprise_ohe'].loc['2016':'2019'].abs().max()\n",
    "df['surprise_ohe'] = df['surprise_ohe'].fillna(0.0)\n",
    "\n",
    "df['change_ohe'] = df['change_ohe']/df['change_ohe'].loc['2016':'2019'].abs().max()\n",
    "df['change_ohe'] = df['change_ohe'].fillna(0.0)\n",
    "\n",
    "df['after_counter_ohe'] = df['after_counter_ohe']/df['after_counter_ohe'].loc['2016':'2019'].abs().max()\n",
    "df['after_counter_ohe'] = df['after_counter_ohe'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>c_eur</th>\n",
       "      <th>c_gbp</th>\n",
       "      <th>c_jpy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:00:00</th>\n",
       "      <td>1.087891</td>\n",
       "      <td>1.473633</td>\n",
       "      <td>0.831543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:05:00</th>\n",
       "      <td>1.086914</td>\n",
       "      <td>1.474609</td>\n",
       "      <td>0.831543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:10:00</th>\n",
       "      <td>1.086914</td>\n",
       "      <td>1.474609</td>\n",
       "      <td>0.831543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:15:00</th>\n",
       "      <td>1.086914</td>\n",
       "      <td>1.474609</td>\n",
       "      <td>0.831543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03 22:20:00</th>\n",
       "      <td>1.086914</td>\n",
       "      <td>1.474609</td>\n",
       "      <td>0.831543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:35:00</th>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.325195</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:40:00</th>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.325195</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:45:00</th>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.326172</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:50:00</th>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.326172</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:55:00</th>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.326172</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        c_eur     c_gbp     c_jpy\n",
       "                         mean      mean      mean\n",
       "ctime                                            \n",
       "2016-01-03 22:00:00  1.087891  1.473633  0.831543\n",
       "2016-01-03 22:05:00  1.086914  1.474609  0.831543\n",
       "2016-01-03 22:10:00  1.086914  1.474609  0.831543\n",
       "2016-01-03 22:15:00  1.086914  1.474609  0.831543\n",
       "2016-01-03 22:20:00  1.086914  1.474609  0.831543\n",
       "...                       ...       ...       ...\n",
       "2019-12-31 21:35:00  1.121094  1.325195  0.920410\n",
       "2019-12-31 21:40:00  1.121094  1.325195  0.920410\n",
       "2019-12-31 21:45:00  1.121094  1.326172  0.920410\n",
       "2019-12-31 21:50:00  1.121094  1.326172  0.920410\n",
       "2019-12-31 21:55:00  1.121094  1.326172  0.920410\n",
       "\n",
       "[298829 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label = df_label.astype('float16')\n",
    "df = df.astype('float16')\n",
    "df_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=864\n",
    "target_size=85 # this is defined by the network, and not the network is defined by this\n",
    "shift=1\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label data begins from the end of the first train data\n",
    "\n",
    "def ds_input(df, concat_tops, feature_to_last):\n",
    "    nx = df.to_numpy()\n",
    "    if (isinstance(df.columns, pd.core.index.MultiIndex) and concat_tops==False):\n",
    "        top_level_nb = len(df.columns.get_level_values(0).unique())\n",
    "        sub_level_nb = len(df.columns.get_level_values(1).unique())\n",
    "        nx = nx.reshape(-1,top_level_nb,sub_level_nb)\n",
    "        if feature_to_last == True:\n",
    "            nx = np.moveaxis(nx, [0,1,2], [0,2,1])\n",
    "        nx = np.squeeze(nx)\n",
    "    return nx\n",
    "\n",
    "def make_ds(batch_size, time_steps, shift, skip_steps, df, concat_tops=False, feature_to_last=True):\n",
    "    nx = ds_input(df, concat_tops, feature_to_last)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(nx[skip_steps:])\n",
    "    ds = ds.window(time_steps, shift=shift, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(time_steps))\n",
    "    return ds.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_label = make_ds(batch_size=batch_size,\n",
    "                   time_steps=target_size, \n",
    "                   shift=shift, \n",
    "                   skip_steps=train_size, \n",
    "                   df=df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['c_eur', 'c_gbp', 'c_jpy', 'month', 'dow', 'hour', 'event_cur', 'event_exist', 'actual_ohe', 'surprise_ohe', 'change_ohe', 'after_counter_ohe']\n",
    "input_dataset_args = {'batch_size':batch_size,\n",
    "                      'time_steps':train_size,\n",
    "                      'shift':shift, \n",
    "                      'skip_steps':0}\n",
    "\n",
    "ds_bars_feat_end = make_ds(**input_dataset_args, df=df[['c_eur', 'c_gbp', 'c_jpy']])\n",
    "ds_bars_curr_end = make_ds(**input_dataset_args, df=df[['c_eur', 'c_gbp', 'c_jpy']], concat_tops=False, feature_to_last=False)\n",
    "ds_bars_simple = make_ds(**input_dataset_args, df=df[['c_eur', 'c_gbp', 'c_jpy']], concat_tops=True)\n",
    "ds_event_ohe = make_ds(**input_dataset_args, df=df[['actual_ohe','surprise_ohe','change_ohe','after_counter_ohe']], concat_tops=True) # for simplicity\n",
    "ds_event_exist = make_ds(**input_dataset_args, df=df['event_exist'])\n",
    "ds_time_cur = make_ds(**input_dataset_args, df=df[['month', 'dow', 'hour', 'event_cur']], concat_tops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_input_full = make_ds(**input_dataset_args, df=df[['c_eur', 'c_gbp', 'c_jpy', \n",
    "                                                     'month', 'dow', 'hour', \n",
    "                                                     'event_cur',\n",
    "                                                     'event_exist','actual_ohe','surprise_ohe','change_ohe','after_counter_ohe']], concat_tops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_event_future = make_ds(  batch_size=batch_size,\n",
    "                            time_steps=target_size, \n",
    "                            shift=shift, \n",
    "                            skip_steps=train_size, \n",
    "                            df=df['event_exist'])\n",
    "ds_time_curr_future = make_ds(  batch_size=batch_size,\n",
    "                            time_steps=target_size, \n",
    "                            shift=shift, \n",
    "                            skip_steps=train_size, \n",
    "                            df=df[['month', 'dow', 'hour', 'event_cur']], concat_tops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_label  <BatchDataset shapes: (64, None, 3), types: tf.float16>\n",
      "ds_bars_feat_end  <BatchDataset shapes: (64, None, 11, 3), types: tf.float16>\n",
      "ds_bars_curr_end  <BatchDataset shapes: (64, None, 3, 11), types: tf.float16>\n",
      "ds_bars_simple  <BatchDataset shapes: (64, None, 33), types: tf.float16>\n",
      "ds_event_ohe  <BatchDataset shapes: (64, None, 280), types: tf.float16>\n",
      "ds_time_cur <BatchDataset shapes: (64, None, 46), types: tf.float16>\n",
      "ds_event_exist  <BatchDataset shapes: (64, None, 70), types: tf.float16>\n",
      "ds_event_future  <BatchDataset shapes: (64, None, 70), types: tf.float16>\n",
      "ds_time_curr_future  <BatchDataset shapes: (64, None, 46), types: tf.float16>\n",
      "ds_input_full  <BatchDataset shapes: (64, None, 429), types: tf.float16>\n"
     ]
    }
   ],
   "source": [
    "print('ds_label ',ds_label)\n",
    "\n",
    "print('ds_bars_feat_end ',ds_bars_feat_end) # not used\n",
    "print('ds_bars_curr_end ',ds_bars_curr_end) # not used\n",
    "print('ds_bars_simple ',ds_bars_simple)\n",
    "print('ds_event_ohe ', ds_event_ohe) \n",
    "# more than one ocasion per number => no entity embedding\n",
    "print('ds_time_cur', ds_time_cur) \n",
    "print('ds_event_exist ', ds_event_exist)\n",
    "# \n",
    "print('ds_event_future ', ds_event_future)\n",
    "print('ds_time_curr_future ', ds_time_curr_future)\n",
    "#\n",
    "print('ds_input_full ', ds_input_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedActivationUnit(keras.layers.Layer):\n",
    "    def __init__(self, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def call(self, inputs):\n",
    "        n_filters = inputs.shape[-1] // 2\n",
    "        linear_output = self.activation(inputs[..., :n_filters])\n",
    "        gate = keras.activations.sigmoid(inputs[..., n_filters:])\n",
    "        return self.activation(linear_output) * gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavenet_residual_block(inputs, n_filters, dilation_rate):\n",
    "    z = keras.layers.Conv1D(2 * n_filters, kernel_size=2, padding=\"causal\",\n",
    "                            dilation_rate=dilation_rate)(inputs)\n",
    "    z = GatedActivationUnit()(z)\n",
    "    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)\n",
    "    return keras.layers.Add()([z, inputs]), z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "input_c1 = keras.layers.Input(shape=[train_size, 11, 3])\n",
    "input_c2 = keras.layers.Input(shape=[train_size, 3, 11])\n",
    "input_simple_c = keras.layers.Input(shape=[train_size, 33])\n",
    "input_ohe = keras.layers.Input(shape=[train_size, 280])\n",
    "input_time_cur = keras.layers.Input(shape=[train_size, 46])\n",
    "input_event_exist = keras.layers.Input(shape=[train_size, 70])\n",
    "\n",
    "\n",
    "input_f_time_cur = keras.layers.Input(shape=[target_size, 46])\n",
    "input_f_event_exist = keras.layers.Input(shape=[target_size, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_cur_cross_in\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 864, 11, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 864, 3, 11)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 864, 11, 6)   24          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 864, 3, 22)   264         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 864, 66)      0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 864, 66)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 864, 132)     0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 288\n",
      "Trainable params: 288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# not used\n",
    "def curr_cross_input_model(input1, input2):\n",
    "    z1 = keras.layers.Conv2D(2*3, kernel_size=1, padding=\"valid\")(input1)\n",
    "    z1 = keras.layers.Reshape([train_size,66])(z1)\n",
    "    \n",
    "    z2 = keras.layers.Conv2D(2*11, kernel_size=1, padding=\"valid\")(input2)\n",
    "    z2 = keras.layers.Reshape([train_size,66])(z2)\n",
    "    \n",
    "    out = keras.layers.Concatenate(axis=-1)([z1, z2])\n",
    "    return keras.models.Model(inputs=[input1, input2], outputs=[out])\n",
    "\n",
    "model_cur_cross_in = curr_cross_input_model(input_c1, input_c2)\n",
    "model_cur_cross_in._name = 'model_cur_cross_in'\n",
    "\n",
    "model_cur_cross_in.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_event_exist\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 864, 70)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 864, 10)           710       \n",
      "=================================================================\n",
      "Total params: 710\n",
      "Trainable params: 710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def event_exist_model(inputs):\n",
    "    out = keras.layers.Conv1D(10, kernel_size=1, strides=1, padding='valid')(inputs)\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model_event_exist = event_exist_model(input_event_exist)\n",
    "model_event_exist._name = 'model_event_exist'\n",
    "\n",
    "model_event_exist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 864, 46)\n",
      "Model: \"model_time_cur\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 864, 46)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 864, 6)            282       \n",
      "=================================================================\n",
      "Total params: 282\n",
      "Trainable params: 282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def time_cur_model(inputs):\n",
    "    print(inputs.shape)\n",
    "    out = keras.layers.Conv1D(6, kernel_size=1, strides=1, padding='valid')(inputs)\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model_time_cur = time_cur_model(input_time_cur)\n",
    "model_time_cur._name = 'model_time_cur'\n",
    "\n",
    "model_time_cur.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_event_ohe\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 864, 280)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 864, 16)           4496      \n",
      "=================================================================\n",
      "Total params: 4,496\n",
      "Trainable params: 4,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def event_ohe_input_model(inputs):\n",
    "    out = keras.layers.Conv1D(16, kernel_size=1, strides=1, padding='valid')(inputs)\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model_event_ohe = event_ohe_input_model(input_ohe)\n",
    "model_event_ohe._name = 'model_event_ohe'\n",
    "\n",
    "model_event_ohe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_wavenet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 864, 65)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 864, 32)      4192        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 864, 64)      4160        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit (GatedAct (None, 864, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 864, 32)      1056        gated_activation_unit[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 864, 32)      0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 864, 64)      4160        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_1 (GatedA (None, 864, 32)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 864, 32)      1056        gated_activation_unit_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 864, 32)      0           conv1d_7[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 864, 64)      4160        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_2 (GatedA (None, 864, 32)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 864, 32)      1056        gated_activation_unit_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 864, 32)      0           conv1d_9[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 864, 64)      4160        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_3 (GatedA (None, 864, 32)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 864, 32)      1056        gated_activation_unit_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 864, 32)      0           conv1d_11[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 864, 64)      4160        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_4 (GatedA (None, 864, 32)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 864, 32)      1056        gated_activation_unit_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 864, 32)      0           conv1d_13[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 864, 64)      4160        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_unit_5 (GatedA (None, 864, 32)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 864, 32)      1056        gated_activation_unit_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 864, 32)      0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu (TensorFlowOpL [(None, 864, 32)]    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 864, 32)      1056        tf_op_layer_Relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 864, 3)       99          conv1d_16[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 36,643\n",
      "Trainable params: 36,643\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def wavenet_model(n_layers_per_block, n_blocks, n_filters, n_outputs):\n",
    "    # n_layers_per_block = 10 in the paper\n",
    "    # n_blocks = 3 in the paper\n",
    "    # n_filters = 128 in the paper\n",
    "    # n_outputs = 256 in the paper\n",
    "    \n",
    "    inputs = keras.layers.Input(shape=[train_size, 65]) # 164 with cross model\n",
    "    z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)\n",
    "    skip_to_last = []\n",
    "    for dilation_rate in [2**i for i in range(n_layers_per_block)] * n_blocks:\n",
    "        z, skip = wavenet_residual_block(z, n_filters, dilation_rate)\n",
    "        skip_to_last.append(skip)\n",
    "    z = keras.activations.relu(keras.layers.Add()(skip_to_last))\n",
    "    z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)\n",
    "    Y_proba = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=\"softmax\")(z)\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[Y_proba])\n",
    "\n",
    "model_wn = wavenet_model(n_layers_per_block=3, n_blocks=2, n_filters=32, n_outputs=3)\n",
    "# (fast test) #  model_wn = wavenet_model(n_layers_per_block=2, n_blocks=1, n_filters=1, n_outputs=3)\n",
    "model_wn._name = 'model_wavenet'\n",
    "\n",
    "#keras.utils.plot_model(model, show_shapes=True)\n",
    "model_wn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_head\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 864, 3)]          0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 172, 3)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 85, 3)             30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def head_model():\n",
    "    inputs = keras.layers.Input(shape=[train_size, 3])\n",
    "    z = keras.layers.AveragePooling1D(pool_size=5, strides=5, padding='valid', data_format='channels_last')(inputs)\n",
    "    out = keras.layers.Conv1D(3, kernel_size=3, strides=2, padding='valid')(z)\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model_head = head_model()\n",
    "model_head._name = 'model_head'\n",
    "\n",
    "model_head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_5:0\", shape=(None, 864, 46), dtype=float32) for input (None, 864, 46), but it was re-called on a Tensor with incompatible shape (None, 85, 46).\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_6:0\", shape=(None, 864, 70), dtype=float32) for input (None, 864, 70), but it was re-called on a Tensor with incompatible shape (None, 85, 70).\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 864, 280)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 864, 46)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 864, 70)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 864, 33)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_event_ohe (Model)         (None, 864, 16)      4496        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_time_cur (Model)          multiple             282         input_5[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_event_exist (Model)       multiple             710         input_6[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 864, 65)      0           input_3[0][0]                    \n",
      "                                                                 model_event_ohe[1][0]            \n",
      "                                                                 model_time_cur[1][0]             \n",
      "                                                                 model_event_exist[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "model_wavenet (Model)           (None, 864, 3)       36643       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 85, 46)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 85, 70)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_head (Model)              (None, 85, 3)        30          model_wavenet[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 85, 19)       0           model_head[1][0]                 \n",
      "                                                                 model_time_cur[2][0]             \n",
      "                                                                 model_event_exist[2][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 85, 3)        60          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 42,221\n",
      "Trainable params: 42,221\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ohe = model_event_ohe(input_ohe)\n",
    "time_cur = model_time_cur(input_time_cur)\n",
    "event_ex = model_event_exist(input_event_exist)\n",
    "inputs = keras.layers.Concatenate(axis=-1)([input_simple_c, ohe, time_cur, event_ex])\n",
    "wave = model_wn(inputs)\n",
    "out_head = model_head(wave)\n",
    "\n",
    "time_cur_f = model_time_cur(input_f_time_cur)\n",
    "event_ex_f = model_event_exist(input_f_event_exist)\n",
    "\n",
    "input_f = keras.layers.Concatenate(axis=-1)([out_head, time_cur_f, event_ex_f])\n",
    "out_f = keras.layers.Conv1D(3, kernel_size=1, strides=1, padding='valid')(input_f)\n",
    "\n",
    "model_sum = keras.models.Model(inputs=[input_simple_c, input_ohe, input_time_cur, input_event_exist, input_f_time_cur, input_f_event_exist], outputs=[out_f])\n",
    "\n",
    "model_sum.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_finder(model, train_set):  \n",
    "    \"\"\"\n",
    "    Goes trough learning rates and gives back the history object\n",
    "    to find optimal learning rate.\n",
    "    \"\"\"\n",
    "    # check learning rates to find the best\n",
    "    lr_schedule = keras.callbacks.LearningRateScheduler(lambda epoch: 1e-7 * 10**(epoch / 9))\n",
    "    optimizer = keras.optimizers.Adam(lr=1e-7)\n",
    "    model.compile(loss=keras.losses.Huber(),\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"mae\"])\n",
    "    # get history to find the best learning rate\n",
    "    return model.fit(train_set, epochs=60, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_loss_chart(finder_history, xmin, xmax, ymin, ymax):  \n",
    "    # plot the learning rate / loss chart\n",
    "    # the best learning rates are around the lowest smooth part of the curve\n",
    "    plt.semilogx(finder_history.history[\"lr\"], finder_history.history[\"loss\"])\n",
    "    plt.axis([xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_6:0\", shape=(None, 864, 70), dtype=float32) for input (None, 864, 70), but it was re-called on a Tensor with incompatible shape (64, 85, 70).\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_5:0\", shape=(None, 864, 46), dtype=float32) for input (None, 864, 46), but it was re-called on a Tensor with incompatible shape (64, 85, 46).\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_6:0\", shape=(None, 864, 70), dtype=float32) for input (None, 864, 70), but it was re-called on a Tensor with incompatible shape (64, 85, 70).\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_5:0\", shape=(None, 864, 46), dtype=float32) for input (None, 864, 46), but it was re-called on a Tensor with incompatible shape (64, 85, 46).\n",
      "64/64 [==============================] - 122s 2s/step - loss: 0.6548 - mae: 1.1478\n",
      "Epoch 2/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6559 - mae: 1.1485\n",
      "Epoch 3/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.6527 - mae: 1.1455\n",
      "Epoch 4/60\n",
      "64/64 [==============================] - 118s 2s/step - loss: 0.6510 - mae: 1.1433\n",
      "Epoch 5/60\n",
      "64/64 [==============================] - 118s 2s/step - loss: 0.6576 - mae: 1.1509\n",
      "Epoch 6/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.6588 - mae: 1.1523\n",
      "Epoch 7/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.6565 - mae: 1.1488\n",
      "Epoch 8/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6564 - mae: 1.1495\n",
      "Epoch 9/60\n",
      "64/64 [==============================] - 119s 2s/step - loss: 0.6562 - mae: 1.1489\n",
      "Epoch 10/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6514 - mae: 1.1434\n",
      "Epoch 11/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.6466 - mae: 1.1385\n",
      "Epoch 12/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6536 - mae: 1.1464\n",
      "Epoch 13/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.6578 - mae: 1.1508\n",
      "Epoch 14/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.6514 - mae: 1.1434\n",
      "Epoch 15/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.6462 - mae: 1.1387\n",
      "Epoch 16/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6475 - mae: 1.1400\n",
      "Epoch 17/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.6417 - mae: 1.1339\n",
      "Epoch 18/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.6401 - mae: 1.1316\n",
      "Epoch 19/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.6391 - mae: 1.1307\n",
      "Epoch 20/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.6294 - mae: 1.1207\n",
      "Epoch 21/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6260 - mae: 1.1164\n",
      "Epoch 22/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6124 - mae: 1.1012\n",
      "Epoch 23/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.6038 - mae: 1.0928\n",
      "Epoch 24/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.5923 - mae: 1.0795\n",
      "Epoch 25/60\n",
      "64/64 [==============================] - 118s 2s/step - loss: 0.5723 - mae: 1.0596\n",
      "Epoch 26/60\n",
      "64/64 [==============================] - 118s 2s/step - loss: 0.5437 - mae: 1.0291\n",
      "Epoch 27/60\n",
      "64/64 [==============================] - 114s 2s/step - loss: 0.5024 - mae: 0.9867\n",
      "Epoch 28/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.4251 - mae: 0.9001\n",
      "Epoch 29/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.3408 - mae: 0.7988\n",
      "Epoch 30/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.2577 - mae: 0.6828\n",
      "Epoch 31/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.1762 - mae: 0.5553\n",
      "Epoch 32/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.1009 - mae: 0.3976\n",
      "Epoch 33/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.0493 - mae: 0.2620\n",
      "Epoch 34/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.0234 - mae: 0.1751\n",
      "Epoch 35/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.0139 - mae: 0.1320\n",
      "Epoch 36/60\n",
      "64/64 [==============================] - 118s 2s/step - loss: 0.0106 - mae: 0.1154\n",
      "Epoch 37/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.0081 - mae: 0.0994\n",
      "Epoch 38/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.0062 - mae: 0.0879\n",
      "Epoch 39/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.0046 - mae: 0.0748\n",
      "Epoch 40/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.0033 - mae: 0.0631\n",
      "Epoch 41/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.0020 - mae: 0.0494\n",
      "Epoch 42/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.0015 - mae: 0.0428\n",
      "Epoch 43/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 9.0886e-04 - mae: 0.0336\n",
      "Epoch 44/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 6.0290e-04 - mae: 0.0275\n",
      "Epoch 45/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 3.9875e-04 - mae: 0.0228\n",
      "Epoch 46/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 2.6205e-04 - mae: 0.0179\n",
      "Epoch 47/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 2.0357e-04 - mae: 0.0155\n",
      "Epoch 48/60\n",
      "64/64 [==============================] - 115s 2s/step - loss: 3.2072e-04 - mae: 0.0158\n",
      "Epoch 49/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 9.0552e-04 - mae: 0.0142\n",
      "Epoch 50/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.0029 - mae: 0.0183\n",
      "Epoch 51/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 9.2418e-04 - mae: 0.0225\n",
      "Epoch 52/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 7.3042e-04 - mae: 0.0222\n",
      "Epoch 53/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.0019 - mae: 0.0398\n",
      "Epoch 54/60\n",
      "64/64 [==============================] - 116s 2s/step - loss: 0.0013 - mae: 0.0371\n",
      "Epoch 55/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 8.8716e-04 - mae: 0.0309\n",
      "Epoch 56/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 5.6363e-04 - mae: 0.0260\n",
      "Epoch 57/60\n",
      "64/64 [==============================] - 117s 2s/step - loss: 0.0029 - mae: 0.0582\n",
      "Epoch 58/60\n",
      "64/64 [==============================] - 118s 2s/step - loss: 0.4645 - mae: 0.6367\n",
      "Epoch 59/60\n",
      "64/64 [==============================] - 118s 2s/step - loss: 15.0974 - mae: 15.5904\n",
      "Epoch 60/60\n",
      "64/64 [==============================] - 119s 2s/step - loss: 18.0962 - mae: 18.5907\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_worker_test = tf.data.Dataset.zip(((ds_bars_simple, ds_event_ohe, ds_time_cur, ds_event_exist, ds_time_curr_future, ds_event_future), \n",
    "                                 ds_label)).shuffle(64).prefetch(tf.data.experimental.AUTOTUNE).take(64)\n",
    "lr_loss_chart(learning_rate_finder(model_sum, train_set=ds_worker_test), 1e-7, 1, 0, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_worker = tf.data.Dataset.zip(((ds_bars_simple, ds_event_ohe, ds_time_cur, ds_event_exist, ds_time_curr_future, ds_event_future), \n",
    "                                 ds_label)).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "model_sum.compile(loss=keras.losses.Huber(), optimizer=\"adam\", metrics=[\"mae\"])\n",
    "history = model_sum.fit(ds_worker, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_worker = tf.data.Dataset.zip((ds_input_full, ds_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((None, None, 429), (None, None, 3)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_finder(model, train_set):  \n",
    "    \"\"\"\n",
    "    Goes trough learning rates and gives back the history object\n",
    "    to find optimal learning rate.\n",
    "    \"\"\"\n",
    "    # check learning rates to find the best\n",
    "    lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "      lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "    optimizer = keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "    model.compile(loss=keras.losses.Huber(),\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"mae\"])\n",
    "    # get history to find the best learning rate\n",
    "    return model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_loss_chart(finder_history, xmin, xmax, ymin, ymax):  \n",
    "    # plot the learning rate / loss chart\n",
    "    # the best learning rates are around the lowest smooth part of the curve\n",
    "    plt.semilogx(finder_history.history[\"lr\"], finder_history.history[\"loss\"])\n",
    "    plt.axis([xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    444/Unknown - 964s 2s/step - loss: 0.6274 - mae: 1.0926"
     ]
    }
   ],
   "source": [
    "ds_input_full_test = make_ds(**input_dataset_args, df=df[['c_eur', 'c_gbp', 'c_jpy', \n",
    "                                                     'month', 'dow', 'hour', \n",
    "                                                     'event_cur',\n",
    "                                                     'event_exist','actual_ohe','surprise_ohe','change_ohe','after_counter_ohe']][:29880], concat_tops=True)\n",
    "ds_worker_test = tf.data.Dataset.zip((ds_input_full_test, ds_label))\n",
    "model_wn.compile(loss=keras.losses.Huber(), optimizer=\"adam\", metrics=[\"mae\"])\n",
    "lr_loss_chart(learning_rate_finder(model_wn, train_set=ds_worker_test), 1e-8, 1e-4, 0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1336/Unknown - 2931s 2s/step - loss: 0.0013 - mae: 0.0130"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3ac2a154b05e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_wn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHuber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_wn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_wn.compile(loss=keras.losses.Huber(), optimizer=\"adam\", metrics=[\"mae\"])\n",
    "history = model_wn.fit(ds_worker, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
